{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408c8079-1b83-46be-8cda-574052054480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61737ecd-1bba-4147-9b5f-3436ce4e176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabels(file, color = np.array([None]), quantile = sys.float_info.max):\n",
    "    \n",
    "    if color.all() != None:\n",
    "        return [np.mean(color)]\n",
    "    \n",
    "    backup = file\n",
    "    if 'nan' in file:\n",
    "        #print(backup)\n",
    "        return None\n",
    "    file = file.split(\"\\\\\")[1]\n",
    "    file = file.split(\"_\", 16)\n",
    "    file[16] = file[16].split('.', 1)[0]\n",
    "    #remove useless labels\n",
    "    del file[16] #'Random string'\n",
    "    del file[15] #'Body Style'\n",
    "    del file[14] #'Passenger Doors',\n",
    "    del file[13] #'Passenger Capacity'\n",
    "    del file[12] #'Drivetrain'\n",
    "    del file[11] #'Gas Mileage'\n",
    "    del file[10] #'Length, Overall (in)'\n",
    "    del file[9] #'Height, Overall (in)'\n",
    "    del file[8] #'Width, Max w/o mirrors (in)'\n",
    "    del file[7] #'Engine Type'\n",
    "    del file[6] #'Displacement'\n",
    "    #del file[5] #'SAE Net Horsepower @ RPM'\n",
    "    del file[4] #'Front Wheel Size (in)'\n",
    "    del file[3] #'MSRP' Prix\n",
    "    del file[2] #'Year'\n",
    "    del file[1] #'Model'\n",
    "    del file[0]#Make'\n",
    "    \n",
    "    try:\n",
    "        file = [int(float(i)) for i in file]\n",
    "    except Exception as e: #get name of file who raises an error\n",
    "        print(backup)\n",
    "        return None\n",
    "    if(file[0] <= quantile):\n",
    "        return file\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1ebdbd-1131-4a41-a668-014834a9284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_labels(labels):\n",
    "    for i in range(labels.shape[1]):\n",
    "        minimum = labels[:,i].min()\n",
    "        maximum = labels[:,i].max()\n",
    "        print(minimum, maximum)\n",
    "        for j in range(labels.shape[0]):\n",
    "            labels[j,i] = (labels[j,i] - minimum)/(maximum - minimum)\n",
    "    return labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b7f1e0-896b-4edd-aa04-81075b917b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0249) tensor(0.9539)\n"
     ]
    }
   ],
   "source": [
    "num = 3000\n",
    "tensorLab_list = []\n",
    "None_id = []\n",
    "i = 0\n",
    "\n",
    "PATH = 'Data/colorsv3.npy'\n",
    "colors = np.load(PATH)\n",
    "\n",
    "q95_RPM = 460\n",
    "\n",
    "\n",
    "for filename in glob.glob('Data/No_background/*.jpg'):\n",
    "    labels = extractLabels(filename, color = colors[i]) #to extract colors\n",
    "    #labels = extractLabels(filename, quantile = q95_RPM)\n",
    "    if labels != None:\n",
    "        tensorLab_list.append(torch.FloatTensor(labels))\n",
    "    else: None_id.append(i)\n",
    "    i += 1\n",
    "    #if i >= num: break\n",
    "    \n",
    "LabelsTens = torch.stack(tensorLab_list)\n",
    "LabelsTens = Normalize_labels(LabelsTens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f766ee3c-399e-451a-913d-9ae09cbb5b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ----------------------------------------Loading Data---------------------------------------- \n",
      " [---------------------------------------------------------------------------------------------------100%]\n"
     ]
    }
   ],
   "source": [
    "num = 3000\n",
    "image_size = 32\n",
    "total_files = 19921\n",
    "current_perc = 0\n",
    "\n",
    "tensorIm_list = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "for filename in glob.glob('Data/No_background/*.jpg'):\n",
    "    \n",
    "    image=np.array(Image.open(filename))\n",
    "    \n",
    "    lengths = image.shape\n",
    "    gap = np.abs(lengths[0] - lengths[1])\n",
    "    argm = np.argmax(lengths)\n",
    "    if argm == 0:\n",
    "        pads = [int(gap/2),0,int(gap/2),0]\n",
    "    else:\n",
    "        pads = [0,int(gap/2),0,int(gap/2)]\n",
    "    \n",
    "    \n",
    "    transform=T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Pad(pads, fill = 255),\n",
    "        T.Resize(image_size),\n",
    "        T.ToTensor()])\n",
    "    \n",
    "    image = transform(image)\n",
    "    if(i not in None_id): tensorIm_list.append(image)\n",
    "    if math.floor(i/total_files*100) > current_perc:\n",
    "        current_perc += 1\n",
    "        s = '[' + '-'*current_perc + str(current_perc+1) + '%' + ' '*(99-current_perc)+ ']'\n",
    "        print('       ----------------------------------------Loading Data----------------------------------------', '\\n', s)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "    i += 1\n",
    "    #if i >= num: break\n",
    "CarsTens = torch.stack(tensorIm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04cf023c-0ef9-481b-a4c7-86a15e588d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19921, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(CarsTens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2c482e-a80e-4306-8136-f8f4582ab796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c32f2c0ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(CarsTens[161].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5afad4af-9fcd-4690-8a98-3a6acf2ed874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        #return len(self.list_IDs)\n",
    "        return LabelsTens.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        X = CarsTens[index]\n",
    "        y = LabelsTens[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95566ef5-5aea-4a69-985a-601781015a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_component: torch.Size([32, 3, 32, 32]) \n",
      "Y-component: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dl = Train_Dataset()\n",
    "train_loader = torch.utils.data.DataLoader(dl, batch_size=batch_size,shuffle=True)\n",
    "test = next(iter(train_loader))\n",
    "print(f\"X_component: {test[0].shape} \\nY-component: {test[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10031e20-e13a-4d9e-a37d-fd22e2cc05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiffAugment(x, label, policy='color,translation,cutout,flip', channels_first = True, color = False):\n",
    "    initlab = label\n",
    "    if not channels_first:\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "    for p in policy.split(','):\n",
    "        for f in AUGMENT_FNS[p]:\n",
    "            x, label = f(x, label)\n",
    "    if not channels_first:\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "    x = x.contiguous()\n",
    "    \n",
    "    return x, (label if color else initlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3500a8d-45c3-4482-8593-7c5de74da9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_brightness(x, label):\n",
    "    factor = (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)*0.5 - 0.25)\n",
    "    change = torch.unsqueeze(factor.reshape(x.size(0)), dim = -1)\n",
    "    #x = x + factor.repeat(1,3,x.shape[2],x.shape[3])*(torch.mean(x, dim = 1, keepdim = True) != 1.)\n",
    "    x = x + factor.repeat(1,3,x.shape[2],x.shape[3])\n",
    "    return x, (label + change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da04a4c-a611-49e0-b0fb-7c1cb81b0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_saturation(x, label):\n",
    "    x_mean = x.mean(dim=1, keepdim=True)\n",
    "    factor = (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)*2)\n",
    "    change = torch.unsqueeze(factor.reshape(x.size(0)), dim = -1)\n",
    "    x = (x - x_mean) * factor + x_mean\n",
    "    return x, label*change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89938a6-89b3-4e3c-bec1-f8294cd3f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_translation(x, label, ratio=0.05):\n",
    "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
    "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
    "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
    "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0], value = 1.)\n",
    "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2).contiguous()\n",
    "    return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67682fa7-feb0-41d2-871a-9d1fc74f857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_cutout(x, label, ratio=0.5):\n",
    "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
    "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
    "    )\n",
    "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
    "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
    "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
    "    mask[grid_batch, grid_x, grid_y] = 0\n",
    "    x = x * mask.unsqueeze(1)\n",
    "    return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24f0f03a-78e3-4851-81d0-18bb6d5c96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_flip(x, label, proba = 0.5):\n",
    "    flips = torch.rand(x.size(0),1,1,1, dtype=x.dtype, device=x.device).repeat(1,3,x.shape[2], x.shape[3])\n",
    "    x = x*(flips <= proba) + torch.flip(x, dims = [3])*(flips > proba)\n",
    "    \n",
    "    return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c18faf1-633e-4076-9494-05c20021d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_FNS = {\n",
    "    'color': [rand_brightness],\n",
    "    'translation': [rand_translation],\n",
    "    'cutout': [rand_cutout],\n",
    "    'flip': [rand_flip],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ec81517-5286-4f53-8ff7-6ac8cf706f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAAFgCAYAAAAcmXr5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARe0lEQVR4nO3d23OdZ3UH4LUl2ZZt+RDLh8QmiUOc09CSZjKUJpBAgLa0t+0FV8AN/1qZoZSrdsKUDiXQIRDCkCZOHMcJdWyIZWPZcmxJ1rkXTKfMrCVlGyteCnmey6V9+La89fOe/fve9xusra0FAHfWSPcBAHwcCV+ABsIXoIHwBWggfAEajH3Az50KwVYyGOI23rNsJeu+Z33yBWggfAEaCF+ABsIXoMEHFW7wkTIYDNPJ/WmxRcBHk0++AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0AD4QvQQPgCNBC+AA2EL0CDse4D2GrWYq2erxXz1TxbXV1Ns+WVpfx4y/l2a8XjxSDPBuURRsRI/klxODE6lv/Zx7bl2cjoaHE8+TlG1j8iYB0++QI0EL4ADYQvQAPhC9DgY1O4VTXa/Nxcmp1792x5/ytTU2l24+q1PLt+Pc2WFxfTrOjGojrKwSD//7i9KMwiInbtGM/3Hy9mxf137d6dZnv37UuzQ8eOpdldByfTbHR0vf/XlXN3yo9/8uM020rFccQ674am4vgLzzxbHc2HxidfgAbCF6CB8AVoIHwBGgzKL+D/34Y/3KqWlpfT7J23z6TZL156Kd93Jd83IuLeT+Si6bXXXk+zqamLaXb8+P1pdvTo0TR768zpNJsrCrzVqd+Vx/hkURg88fnPp9m535xPs7GivNi7d2+aXb6Un/vI4UNp9uDDD5XHOLZtezkf0ge2dYPBOs3On7Dvf//75bwqj7dScRxRl8dbqTiOqMvjZ4Yv59ZfkDrsIwCweYQvQAPhC9BA+AI02Lor3IoisGpSrl9/P81+/KMX0uy9omh4/Im/SLOHTjxYHs7sbF4Nd+qtt9Ns8sjhNHv3t79Ns2P33Ztm1eubvXApP8eeXIRFRIwfOpJmC8srabZ9fGeaXbqYi8K9+/bn5y5e33//6pU0myhKk4iIw/ffl2Zj27almXVww/uX7/5zOa/K46o4Pnn212l2J4rjiLo8Lovjz342zarieK0o4dZ25JL3jTfeSLOqOI5Yvzy+XT75AjQQvgANhC9AA+EL0GDLFm5V+XTu7Ltp9r3vfTfNduzMhdJX/+7v02zywIE0W1rO2+ZFRLxefEE/PT2dZtUKm/n5+TT76U9fTLOZC++l2fhMLhTn9+8vj/F/Xn81za7/Lhd2R44fT7PVYhvA6WI12+LsjTRbuHo1zc786lflMd64km9736ceTbOduyfK+5M9/Nhj5bwqj7dScRxRl8dbqTiOqMvjH/7wh2lWFcfPPvNM+ZgRPvkCtBC+AA2EL0AD4QvQ4EMr3Kov3dfWigsxRcTywkKavX91Js1e/q+fpNnijdk0m9ixI81e+VkuuKryoVrZExEx837edm95JZcA8zP5dmPF6569nMu61Yu5lFgoLl71yssvl8d4eiXf9sChg2n2l8/kbSZXFnPReL1YZ7ZzVy4UtxW/h7nidxsRMV8Udlcu5mLvngfy84wU190i4tGHHynnVXm8lYrjiLo83krFcURdHg9bHG/EJ1+ABsIXoIHwBWggfAEaCF+ABn/EBTTzaLV4jOtXZtJs+sKF8knmZvJtlxZuplnVyC8t5Yv6LRYX+lspL4yZ/+9Z74yMhZv5jIylpXw8y8UxXp7KyzKnzp7L9y1e8/SNvA/q9v13lcd49HBeMrl3V16mu2ciN9mXr82k2SOf+rM0GxnLSygvXS72HJ6sL0Z47VpuvVeKqzB+7VvfSrPR0VEX0Cx86+tfL+fVmTvDnrVT5cLyWr7d4mw+A2Kh2Gd3tDhrJyLiwkL+W925yWftjA951s7iOhfPrZYnHy32pT50f97v+Gvf+LoLaAJsJcIXoIHwBWggfAEa3PLy4mL1Xlw4n8ujn/3rv6XZtWIZaUREFF/4LxdLI6sibamYVd9wV6XgQnHfKPYCjojYvjvPZ6/m1zN99jf5eWZzkbZ7Ihdh9z+SL9R3fP+n0mxi7zoX0Ny9K82qmqMqvX5blKEnXz2ZZpcu5guR3iiWEk/ec095jOeKZaJ/+5Uvp9nqan5PjI6Olo/5cXdsnQuqHi3eY5teHF/Oy2yXJ/akWVUcR0Q8ULxPhi2Ot83lv6trRXF87DaK44iIwbb8vnvz1Kk0e/30m2n2tW/UZWiET74ALYQvQAPhC9BA+AI0uOXCbbFYhfXr1/OXz7/8Zd4D81qxki0iYuVmXiWzWMyWi4JspGiUBsUqteXi8XYczF/sf/JzT5fHuOeuXLiNTOeicbbYc3apaACnruY9VK+czGXI577wXL7v7y6Xx3j6hbxX64Vib9Xrxb6lK0WTOrpje5rt3pPLlIm79qfZ9EL+fUdEPPDpXCDuLFYQDUaUa8P6+X/8oP5BUR7fVnFcFFy7iwudDlscR9Tl8R0pjmdzAZh3+P29yZEck1OreTXcc088sc4j1HzyBWggfAEaCF+ABsIXoMGGhVu1DeO7Z86k2fT5/OV87M3FzNQ6F6g7+Il70+zKVF5Jdb3YDm98W16pMlmUXnu259tNPPpwms3ezKVCRMTqmbNptqPolO46kLe+m7mZS683p6+k2Y2LeQvAN8/nVUU76935Yvt4vnBodSHEyWPH0qzaWfRa8ft+/3ouKm7O59/ZI09/tjzGL/3NX6fZcrECcGTE54JhvfNuLn4j6vL4torj4jmmqguinswFV1UcR9TlcVkcFwV1tWYur4uMqKrb/FcRkavD35suyrVjx/LKvKo43oh3OEAD4QvQQPgCNBC+AA02LNzmZmfT7PnvfCfN9hXlyAPjeZXKoYdOlM9zriiaHpw8kGb7783XTRoUK+7miq3h5sfySx0UBeDcxXW2lRstVoBN5NU5Y9vzqrB338pbzR0orvd0tFiR9Narr6bZwZFcHkZETOzK13Z7fy7/G1bFXrVdZ3W9vpFiW8f54vpcozty+RcRcc/RT6TZoUOH0uwDL9a2juraYz/60X+m2dtv5FLn1Is/T7OXTuXbRUScLkqug8XruLjJxfFE8X6viuOIujze7OL4fLEdbBTbUb7zg38vj7EKoPwXFJHTJGKyWAVZFsfFtefy2ri6rIuI+OS9+T07bHG8EZ98ARoIX4AGwheggfAFaLBh4VZ8dx1n3sor3N47l8uHhx7K28rt3jlePs+BYvXZ2lJeVbJ6fSbNBsVB7tq/P8+qbSaX8lfsg6I8iog4/17edm/25tk0u16UlFdGcnHy5a98Js3uvz8Xihd/cz7N5i7U18K7eT7fdq0oQ8utIidzwbL3YC7wJvbtS7NXTr6WZheKoiki4uzZs2n28MO5MBoUZdMfa7OL44i6PN5KxXFEXR7fVnFcvL92FLcbL4rja9dyyRgRkf/K65VmVUG2WFzn78NQlcfDFscb8ckXoIHwBWggfAEaCF+ABhsWbtuLL9NPPPZomr34i5fS7HRRuIyM1dflGh8vtrkrSqqxohCpCrcdS3mFzehyni2v5DvfXK4qgIiV4jGr564qgF1FkXb8vjw7cuTuNDu4Pxc2l2aq+iFiYnIyP3d1jay9udIY35U32RsfzwVp9Z54oigk9hbPGxFx9935Nd5qUXGrhi6Oi+t/PXT8ePmYVXm8lYrjiLo8Pl+UtbNRrMIrHq+6Kt/TnxmuOP72P327PMbKzNC3HM6eoqSsiuML03nbyoi6PB62ON6IT74ADYQvQAPhC9BA+AI02LBw27Ytlytf/Yd/TLN9B/PqqDNvnEqzl1/6Rfk8V6/NpNlyURasFIXbSlFALBb33V2smBod5AJwZbnaWjFiz558Tbpq+7pLxXaBUaxeqjZNHC22a9y5Jxdhd594sDzG/UcOp9m2oiCb2J0LtyNHjqTZ8aJsOnEir+y6rygPDxzIRWFExI6inNvM1WyVYYvj14rCbbooVu6U6o+zqqzrinj9LRI307DF8cRoHTU3iutEVp8Id43lMnOzi+PBOtugVuXxZhTHPvkCNBC+AA2EL0AD4QvQQPgCNNjwbIeqfT/x2GNpNlEsgzxcXCDy4vxc+TwLp0+n2fai3Zwsls+uLedOd3mpOGOhODVhcXEhzcarUxgiYnQst6OLRVM7N38jH89cft1TF/OSxaszeV/Wuw7nsxDWO5Pg2LFjaVadnfDgg/lsiepsh+oMj7FiqeZWt9ln7UREvHzyZJrld9Ptqc5iqHabrhft12c7VJderd7x651Bkf3xZ+1ERIzM5zOBttJZOxH131t11s6zzz5b3n89PvkCNBC+AA2EL0AD4QvQ4Jbbk4Wb+QvyqWK/y/mbuX74q6eeLh/zzz/9eH6ehXz/5WKv3ZWVXCtUs9ViyfFaUa5Vt1tXcf89RWlzsbiw4rnioqNPPvlkmn3zm99Ms6pAiKgLyWpp5Ye9nHer+eIXv5hmq8W/3bDFcURdHr/9zq/TLNdEd6Y4jqjL42GL4+Xib6hyO8VxRF1m3Yni+LnnniuP507yyReggfAFaCB8ARoIX4AGg6p0+gMb/vD/VCXVsEXYrdy2ep5hZ9XrHHZ2K4Z97mqFTLVvaLWi7ONWmP2BYV74UP+Azz//fJqdOpVXs1UXSoyIuHo1l0qzs7Np1lUcr3fbUnH/t995J82q4rgqwqri+PHHc6keUZfHwxbHt7qirMm671mffAEaCF+ABsIXoIHwBWiwKYUb3CGbVrhVXnjhhTS73ZK4qzjeaD6MO1EcR3xkSrPboXAD2EqEL0AD4QvQQPgCNFC48VHyoRZu8CFQuAFsJcIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWggfAEaCF+ABsIXoIHwBWgw9gE/H9yRo4DN4z3LR4JPvgANhC9AA+EL0ED4AjQQvgANhC9AA+EL0ED4AjQQvgANhC9Agw2XFz/11FNrd+pA4IO8+OKLH7h0eDAYeM+yZaytra37nvXJF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGghfgAbCF6CB8AVoIHwBGgzW1ta6jwHgY8cnX4AGwheggfAFaCB8ARoIX4AGwhegwf8C4VkNR8G98fEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes=[]\n",
    "fig=plt.figure(figsize = (5,5))\n",
    "\n",
    "pic = []\n",
    "\n",
    "data = next(iter(train_loader))\n",
    "imgs = data[0]\n",
    "labels = data[1]\n",
    "\n",
    "aug, aug_labels = DiffAugment(imgs, labels, color = True)\n",
    "\n",
    "pic.append(imgs[0].permute(1,2,0))\n",
    "pic.append(aug[0].permute(1,2,0))\n",
    "pic.append(labels[0].reshape(1,1))\n",
    "pic.append(aug_labels[0].reshape(1,1))\n",
    "\n",
    "for i in range(4):    \n",
    "    b = pic[i]\n",
    "    axes.append(fig.add_subplot(2,2,i+1))\n",
    "    if i < 2:\n",
    "        plt.imshow(b)\n",
    "    else:\n",
    "        plt.imshow(b, cmap=\"gray\", vmin=0, vmax=1)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81079e6-44d0-482c-8a90-894512799909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0f5f0-b5d9-441e-a64b-04c35899f3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
