{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans #import a random package to avoid kernel death when using pyplot (makes no sense but works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLabels(file, color = np.array([None]), quantile = sys.float_info.max):\n",
    "    \n",
    "    if color.all() != None:\n",
    "        return [np.mean(color)]\n",
    "    \n",
    "    backup = file\n",
    "    if 'nan' in file:\n",
    "        #print(backup)\n",
    "        return None\n",
    "    file = file.split(\"\\\\\")[1]\n",
    "    file = file.split(\"_\", 16)\n",
    "    file[16] = file[16].split('.', 1)[0]\n",
    "    #remove useless labels\n",
    "    del file[16] #'Random string'\n",
    "    del file[15] #'Body Style'\n",
    "    del file[14] #'Passenger Doors',\n",
    "    del file[13] #'Passenger Capacity'\n",
    "    del file[12] #'Drivetrain'\n",
    "    del file[11] #'Gas Mileage'\n",
    "    del file[10] #'Length, Overall (in)'\n",
    "    del file[9] #'Height, Overall (in)'\n",
    "    del file[8] #'Width, Max w/o mirrors (in)'\n",
    "    del file[7] #'Engine Type'\n",
    "    del file[6] #'Displacement'\n",
    "    #del file[5] #'SAE Net Horsepower @ RPM'\n",
    "    del file[4] #'Front Wheel Size (in)'\n",
    "    del file[3] #'MSRP' Prix\n",
    "    del file[2] #'Year'\n",
    "    del file[1] #'Model'\n",
    "    del file[0]#Make'\n",
    "    \n",
    "    try:\n",
    "        file = [int(float(i)) for i in file]\n",
    "    except Exception as e: #get name of file who raises an error\n",
    "        print(backup)\n",
    "        return None\n",
    "    if(file[0] <= quantile):\n",
    "        return file\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_labels(labels):\n",
    "    for i in range(labels.shape[1]):\n",
    "        minimum = labels[:,i].min()\n",
    "        maximum = labels[:,i].max()\n",
    "        print(minimum, maximum)\n",
    "        for j in range(labels.shape[0]):\n",
    "            labels[j,i] = (labels[j,i] - minimum)/(maximum - minimum)\n",
    "    return labels            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize_labels(labels):\n",
    "    mean = torch.mean(labels)\n",
    "    sd = torch.std(labels)\n",
    "    return (labels - mean)/sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/No_background\\Chevrolet_Volt_2011_40_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_lgT.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2011_40_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_OCX.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2011_40_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_qby.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2011_40_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_ZQr.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2012_39_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_aOM.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2012_39_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_hpF.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2012_39_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_oLC.jpg\n",
      "Data/No_background\\Chevrolet_Volt_2012_39_17_- 0_14_4_70_56_177_35_FWD_4_4_4dr_Wva.jpg\n",
      "tensor(100.) tensor(890.)\n"
     ]
    }
   ],
   "source": [
    "num = 3000\n",
    "tensorLab_list = []\n",
    "None_id = []\n",
    "i = 0\n",
    "\n",
    "PATH = 'Data/colorsv3.npy'\n",
    "colors = np.load(PATH)\n",
    "\n",
    "q95_RPM = 460\n",
    "\n",
    "\n",
    "for filename in glob.glob('Data/No_background/*.jpg'):\n",
    "    #labels = extractLabels(filename, color = colors[i]) #to extract colors\n",
    "    labels = extractLabels(filename, quantile = q95_RPM)\n",
    "    if labels != None:\n",
    "        tensorLab_list.append(torch.FloatTensor(labels))\n",
    "    else: None_id.append(i)\n",
    "    i += 1\n",
    "    #if i >= num: break\n",
    "    \n",
    "LabelsTens = torch.stack(tensorLab_list)\n",
    "#LabelsTens = Standardize_labels(LabelsTens)\n",
    "LabelsTens = Normalize_labels(LabelsTens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15981, 1])\n",
      "tensor([[0.0127],\n",
      "        [0.0127],\n",
      "        [0.0127],\n",
      "        ...,\n",
      "        [0.1899],\n",
      "        [0.1899],\n",
      "        [0.1899]])\n"
     ]
    }
   ],
   "source": [
    "print(LabelsTens.shape)\n",
    "print(LabelsTens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the normalized labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 30 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAT1klEQVR4nO3dcayd9X3f8fdnkCC6lIWUC6K2MzuRSQuoccodQ8sS0bEOh0yFTM1mOgWWojlhZEvV/hHIpKZaZYlsTTKhDiInQYCUQL2SDFchbSltw6pCyCUlGENoDLhwYwvflKlhTeXJ5rs/znOTE3Pse+455x5z/Xu/pKP7nO/ze87z+3Gtz334Pc95nlQVkqQ2/L3j3QFJ0vQY+pLUEENfkhpi6EtSQwx9SWrIyce7A0s544wzav369ce7G5K0qjzyyCPfraqZI+uv+tBfv349c3Nzx7sbkrSqJPmrQXWndySpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGv+m/kamWsv/7LQ7Xbe+O7V7gnkqbJI31JaoihL0kNMfQlqSGGviQ1xNCXpIYsGfpJ1iX5kyRPJtmd5MNd/Q1J7kvy7e7n6X3b3JBkT5KnklzaV78gya5u3U1JsjLDkiQNMsyR/iHg16rqp4GLgOuSnAtcD9xfVRuB+7v3dOu2AOcBm4Gbk5zUfdYtwFZgY/faPMGxSJKWsOR1+lW1H9jfLb+U5ElgDXA5cHHX7HbgT4GPdPW7quog8GySPcCFSfYCp1XVgwBJ7gCuAL4yueFo2OvvJbVpWXP6SdYDbwO+BpzV/UFY/MNwZtdsDfB832bzXW1Nt3xkfdB+tiaZSzK3sLCwnC5Kko5h6NBP8jrgbuBXqup7x2o6oFbHqL+yWLW9qmaranZm5hXP9ZUkjWio0E/yGnqB//mq+mJXfiHJ2d36s4EDXX0eWNe3+VpgX1dfO6AuSZqSYa7eCfA54Mmq+mTfqp3A1d3y1cA9ffUtSU5JsoHeCduHuymgl5Jc1H3mVX3bSJKmYJgbrr0deB+wK8mjXe2jwI3AjiTXAM8B7wWoqt1JdgBP0Lvy57qqOtxtdy1wG3AqvRO4nsSVpCka5uqdP2PwfDzAJUfZZhuwbUB9Djh/OR2UJE2Ot1ZeAcu5bNJbF0uaJm/DIEkNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkOGeVzirUkOJHm8r/Y7SR7tXnsXn6iVZH2Sv+tb9+m+bS5IsivJniQ3dY9MlCRN0TAPUbkN+G3gjsVCVf2bxeUknwD+pq/901W1acDn3AJsBR4C7gU24+MSJWmqljzSr6oHgBcHreuO1v81cOexPiPJ2cBpVfVgVRW9PyBXLLu3kqSxjDun/w7ghar6dl9tQ5K/SPLVJO/oamuA+b42811toCRbk8wlmVtYWBizi5KkReOG/pX86FH+fuCNVfU24FeBLyQ5jcEPVq+jfWhVba+q2aqanZmZGbOLkqRFIz8YPcnJwL8CLlisVdVB4GC3/EiSp4Fz6B3Zr+3bfC2wb9R9S5JGM86R/j8HvlVVP5i2STKT5KRu+U3ARuCZqtoPvJTkou48wFXAPWPsW5I0gmEu2bwTeBB4S5L5JNd0q7bwyhO47wQeS/JN4HeBD1bV4knga4HPAnuAp/HKHUmauiWnd6rqyqPU/92A2t3A3UdpPwecv8z+TcX66788VLu9N757hXsiSSvLb+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDVk5C9ntWjYq3wk6dXKI31JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDRnmyVm3JjmQ5PG+2m8k+U6SR7vXZX3rbkiyJ8lTSS7tq1+QZFe37qbusYmSpCka5kj/NmDzgPqnqmpT97oXIMm59B6jeF63zc2Lz8wFbgG20ntu7sajfKYkaQUtGfpV9QDw4lLtOpcDd1XVwap6lt7zcC9McjZwWlU9WFUF3AFcMWKfJUkjGmdO/0NJHuumf07vamuA5/vazHe1Nd3ykfWBkmxNMpdkbmFhYYwuSpL6jXpr5VuA3wSq+/kJ4JeBQfP0dYz6QFW1HdgOMDs7e9R2LfG2zpImYaQj/ap6oaoOV9XLwGeAC7tV88C6vqZrgX1dfe2AuiRpikYK/W6OftF7gMUre3YCW5KckmQDvRO2D1fVfuClJBd1V+1cBdwzRr8lSSNYcnonyZ3AxcAZSeaBjwEXJ9lEb4pmL/ABgKranWQH8ARwCLiuqg53H3UtvSuBTgW+0r0kSVO0ZOhX1ZUDyp87RvttwLYB9Tng/GX1TpI0UX4jV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYsGfrdg88PJHm8r/bfknyrezD6l5K8vquvT/J3SR7tXp/u2+aCJLuS7ElyU/cELUnSFA1zpH8bsPmI2n3A+VX1M8BfAjf0rXu6qjZ1rw/21W8BttJ7hOLGAZ8pSVphS4Z+VT0AvHhE7Q+r6lD39iF+9KHnr9A9U/e0qnqwqgq4A7hipB5LkkY2iTn9X+ZHn3e7IclfJPlqknd0tTXAfF+b+a42UJKtSeaSzC0sLEygi5IkGDP0k/xneg9A/3xX2g+8sareBvwq8IUkpwGD5u/raJ9bVduraraqZmdmZsbpoiSpz5IPRj+aJFcD/xK4pJuyoaoOAge75UeSPA2cQ+/Ivn8KaC2wb9R9S5JGM9KRfpLNwEeAX6iq7/fVZ5Kc1C2/id4J22eqaj/wUpKLuqt2rgLuGbv3kqRlWfJIP8mdwMXAGUnmgY/Ru1rnFOC+7srLh7ordd4J/Jckh4DDwAeravEk8LX0rgQ6ld45gP7zAJKkKVgy9KvqygHlzx2l7d3A3UdZNwecv6zeSZImym/kSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IasmToJ7k1yYEkj/fV3pDkviTf7n6e3rfuhiR7kjyV5NK++gVJdnXrbuoemyhJmqJhjvRvAzYfUbseuL+qNgL3d+9Jci6wBTiv2+bmxWfmArcAW+k9N3fjgM+UJK2wJUO/qh4AXjyifDlwe7d8O3BFX/2uqjpYVc8Ce4ALk5wNnFZVD1ZVAXf0bSNJmpJR5/TPqqr9AN3PM7v6GuD5vnbzXW1Nt3xkfaAkW5PMJZlbWFgYsYuSpCNN+kTuoHn6OkZ9oKraXlWzVTU7MzMzsc5JUutGDf0Xuikbup8Huvo8sK6v3VpgX1dfO6AuSZqiUUN/J3B1t3w1cE9ffUuSU5JsoHfC9uFuCuilJBd1V+1c1beNJGlKTl6qQZI7gYuBM5LMAx8DbgR2JLkGeA54L0BV7U6yA3gCOARcV1WHu4+6lt6VQKcCX+lezVt//ZePdxckNWTJ0K+qK4+y6pKjtN8GbBtQnwPOX1bvJEkT5TdyJakhhr4kNcTQl6SGLDmnv5p5klSSfpRH+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyMg3XEvyFuB3+kpvAn4deD3w74GFrv7Rqrq32+YG4BrgMPCfquoPRt2/Vqfl3ARv743vXsGeSG0aOfSr6ilgE0CSk4DvAF8C3g98qqp+q799knOBLcB5wE8Cf5TknL7HKUqSVtikpncuAZ6uqr86RpvLgbuq6mBVPQvsAS6c0P4lSUOYVOhvAe7se/+hJI8luTXJ6V1tDfB8X5v5rvYKSbYmmUsyt7CwMKiJJGkEY4d+ktcCvwD8z650C/BmelM/+4FPLDYdsHkN+syq2l5Vs1U1OzMzM24XJUmdSRzpvwv4RlW9AFBVL1TV4ap6GfgMP5zCmQfW9W23Ftg3gf1LkoY0idC/kr6pnSRn9617D/B4t7wT2JLklCQbgI3AwxPYvyRpSGM9IzfJjwE/D3ygr/xfk2yiN3Wzd3FdVe1OsgN4AjgEXOeVO5I0XWOFflV9H/iJI2rvO0b7bcC2cfYpSRqd38iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhY12nLy1azn3yJR0/HulLUkM80tcxeQQvnVg80pekhhj6ktQQQ1+SGmLoS1JDDH1JashYoZ9kb5JdSR5NMtfV3pDkviTf7n6e3tf+hiR7kjyV5NJxOy9JWp5JHOn/XFVtqqrZ7v31wP1VtRG4v3tPknOBLcB5wGbg5iQnTWD/kqQhrcT0zuXA7d3y7cAVffW7qupgVT0L7OGHD02XJE3BuKFfwB8meSTJ1q52VlXtB+h+ntnV1wDP920739VeIcnWJHNJ5hYWFsbsoiRp0bjfyH17Ve1LciZwX5JvHaNtBtRqUMOq2g5sB5idnR3YRpK0fGMd6VfVvu7nAeBL9KZrXkhyNkD380DXfB5Y17f5WmDfOPuXJC3PyKGf5O8n+fHFZeBfAI8DO4Gru2ZXA/d0yzuBLUlOSbIB2Ag8POr+JUnLN870zlnAl5Isfs4Xqur3k3wd2JHkGuA54L0AVbU7yQ7gCeAQcF1VHR6r95KkZRk59KvqGeCtA+p/DVxylG22AdtG3ackaTx+I1eSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JBxHpe4LsmfJHkyye4kH+7qv5HkO0ke7V6X9W1zQ5I9SZ5KcukkBiBJGt44j0s8BPxaVX2je1buI0nu69Z9qqp+q79xknOBLcB5wE8Cf5TkHB+ZKEnTM/KRflXtr6pvdMsvAU8Ca46xyeXAXVV1sKqeBfYAF466f0nS8k1kTj/JeuBtwNe60oeSPJbk1iSnd7U1wPN9m81zlD8SSbYmmUsyt7CwMIkuSpKYQOgneR1wN/ArVfU94BbgzcAmYD/wicWmAzavQZ9ZVduraraqZmdmZsbtoiSpM1boJ3kNvcD/fFV9EaCqXqiqw1X1MvAZfjiFMw+s69t8LbBvnP1LkpZn5BO5SQJ8Dniyqj7ZVz+7qvZ3b98DPN4t7wS+kOST9E7kbgQeHnX/0qL11395qHZ7b3z3CvdEevUb5+qdtwPvA3YlebSrfRS4MskmelM3e4EPAFTV7iQ7gCfoXflznVfuSNJ0jRz6VfVnDJ6nv/cY22wDto26T7Vl2CP4E8Vyxuv/tWhUfiNXkhpi6EtSQ8aZ05ea5glkrUYe6UtSQzzSVzM8Mpc80pekphj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xC9nSUdYDXf39ItmGpWhL2ni/KP06uX0jiQ1ZOqhn2RzkqeS7Ely/bT3L0ktm+r0TpKTgP8B/Dy9B6V/PcnOqnpimv2Qpmk1nCM4kTi1dGzTntO/ENhTVc8AJLkLuJzec3MlTdik/+BMOihPpD+Ir/b/1oumHfprgOf73s8D//jIRkm2Alu7t/83yVMj7u8M4LsjbrtaOeY2HJcx5+PT3uMPTHy8x3EsQ8nHxx7zPxxUnHboD3qQer2iULUd2D72zpK5qpod93NWE8fchtbG3Np4YeXGPO0TufPAur73a4F9U+6DJDVr2qH/dWBjkg1JXgtsAXZOuQ+S1KypTu9U1aEkHwL+ADgJuLWqdq/gLseeIlqFHHMbWhtza+OFFRpzql4xpS5JOkH5jVxJaoihL0kNOSFCf6lbO6Tnpm79Y0l+9nj0c1KGGO+/7cb5WJI/T/LW49HPSRr29h1J/lGSw0l+cZr9WwnDjDnJxUkeTbI7yVen3cdJG+Lf9j9I8ntJvtmN+f3Ho5+TkuTWJAeSPH6U9ZPPrqpa1S96J4SfBt4EvBb4JnDuEW0uA75C73sCFwFfO979XuHx/hPg9G75Xat5vMOOua/dHwP3Ar94vPs9hd/z6+l9m/2N3fszj3e/pzDmjwIf75ZngBeB1x7vvo8x5ncCPws8fpT1E8+uE+FI/we3dqiq/wcs3tqh3+XAHdXzEPD6JGdPu6MTsuR4q+rPq+r/dG8fovd9iNVsmN8xwH8E7gYOTLNzK2SYMf8S8MWqeg6gqlb7uIcZcwE/niTA6+iF/qHpdnNyquoBemM4moln14kQ+oNu7bBmhDarxXLHcg29I4XVbMkxJ1kDvAf49BT7tZKG+T2fA5ye5E+TPJLkqqn1bmUMM+bfBn6a3pc6dwEfrqqXp9O942Li2XUiPERlmFs7DHX7h1Vi6LEk+Tl6of9PV7RHK2+YMf934CNVdbh3ELjqDTPmk4ELgEuAU4EHkzxUVX+50p1bIcOM+VLgUeCfAW8G7kvyv6vqeyvct+Nl4tl1IoT+MLd2OJFu/zDUWJL8DPBZ4F1V9ddT6ttKGWbMs8BdXeCfAVyW5FBV/a+p9HDyhv13/d2q+lvgb5M8ALwVWK2hP8yY3w/cWL0J7z1JngV+Cnh4Ol2cuoln14kwvTPMrR12Ald1Z8IvAv6mqvZPu6MTsuR4k7wR+CLwvlV81NdvyTFX1YaqWl9V64HfBf7DKg58GO7f9T3AO5KcnOTH6N2x9skp93OShhnzc/T+z4YkZwFvAZ6Zai+na+LZteqP9Osot3ZI8sFu/afpXc1xGbAH+D69o4VVacjx/jrwE8DN3ZHvoVrFdygccswnlGHGXFVPJvl94DHgZeCzVTXw0r/VYMjf828CtyXZRW/q4yNVtWpvq53kTuBi4Iwk88DHgNfAymWXt2GQpIacCNM7kqQhGfqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIf8fh0XXIEusJSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(LabelsTens.view(-1).tolist(), np.arange(torch.min(LabelsTens),torch.max(LabelsTens)+1/30,1/30))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ----------------------------------------Loading Data---------------------------------------- \n",
      " [---------------------------------------------------------------------------------------------------100%]\n"
     ]
    }
   ],
   "source": [
    "num = 3000\n",
    "image_size = 128\n",
    "total_files = 19921\n",
    "current_perc = 0\n",
    "\n",
    "tensorIm_list = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "for filename in glob.glob('Data/No_background/*.jpg'):\n",
    "    \n",
    "    image=np.array(Image.open(filename))\n",
    "    \n",
    "    lengths = image.shape\n",
    "    gap = np.abs(lengths[0] - lengths[1])\n",
    "    argm = np.argmax(lengths)\n",
    "    if argm == 0:\n",
    "        pads = [int(gap/2),0,int(gap/2),0]\n",
    "    else:\n",
    "        pads = [0,int(gap/2),0,int(gap/2)]\n",
    "    \n",
    "    \n",
    "    transform=T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Pad(pads, fill = 255),\n",
    "        T.Resize(image_size),\n",
    "        T.ToTensor()])\n",
    "    \n",
    "    image = transform(image)\n",
    "    if(i not in None_id): tensorIm_list.append(image)\n",
    "    if math.floor(i/total_files*100) > current_perc:\n",
    "        current_perc += 1\n",
    "        s = '[' + '-'*current_perc + str(current_perc+1) + '%' + ' '*(99-current_perc)+ ']'\n",
    "        print('       ----------------------------------------Loading Data----------------------------------------', '\\n', s)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        \n",
    "    i += 1\n",
    "    #if i >= num: break\n",
    "CarsTens = torch.stack(tensorIm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15332, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(CarsTens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea19f56fa0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(CarsTens[659].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperation dataset into train/test with 80/20% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_images = CarsTens.shape[0]\n",
    "nb_im_train = int(nb_images*.8)\n",
    "\n",
    "ids = np.arange(nb_images)\n",
    "train_ids = np.random.choice(ids, nb_im_train, replace = False)\n",
    "test_ids = np.array([i for i in ids if i not in train_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: 15332 \n",
      "train_ids: 12265 \n",
      "test_ids: 3067\n"
     ]
    }
   ],
   "source": [
    "print(f\"ids: {ids.shape[0]} \\ntrain_ids: {train_ids.shape[0]} \\ntest_ids: {test_ids.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset_Embed(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        #return len(self.list_IDs)\n",
    "        return train_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        idx = train_ids[index]\n",
    "        X = CarsTens[index]\n",
    "        y = LabelsTens[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dl = Train_Dataset_Embed()\n",
    "train_loader = torch.utils.data.DataLoader(dl, batch_size=batch_size,shuffle=True)\n",
    "test = next(iter(train_loader))\n",
    "print(test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset_Embed(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        #return len(self.list_IDs)\n",
    "        return test_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        idx = test_ids[index]\n",
    "        X = CarsTens[index]\n",
    "        y = LabelsTens[index]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dl = Test_Dataset_Embed()\n",
    "test_loader = torch.utils.data.DataLoader(dl, batch_size=batch_size,shuffle=True)\n",
    "test = next(iter(test_loader))\n",
    "print(test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Embedding:\n",
    "\n",
    "-train a classifier Image->feature <br>\n",
    "-use the linear part dim_embed->1 to train the embeding network y2h with MSE loss on recronstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC = 3\n",
    "IMG_SIZE = 128\n",
    "DIM_EMBED = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes: #if True we add a residual part to the block\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_embed(nn.Module):\n",
    "    def __init__(self, block, num_blocks, nc=NC, dim_embed=DIM_EMBED):\n",
    "        super(ResNet_embed, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, 64, kernel_size=3, stride=1, padding=1, bias=False),  # h=h\n",
    "            # nn.Conv2d(nc, 64, kernel_size=4, stride=2, padding=1, bias=False),  # h=h/2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2), #h=h/2 64\n",
    "            # self._make_layer(block, 64, num_blocks[0], stride=1),  # h=h\n",
    "            self._make_layer(block, 64, num_blocks[0], stride=2),  # h=h/2 32\n",
    "            self._make_layer(block, 128, num_blocks[1], stride=2), # h=h/2 16\n",
    "            self._make_layer(block, 256, num_blocks[2], stride=2), # h=h/2 8\n",
    "            self._make_layer(block, 512, num_blocks[3], stride=2), # h=h/2 4\n",
    "            # nn.AvgPool2d(kernel_size=4)\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.x2h_res = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, dim_embed),\n",
    "            nn.BatchNorm1d(dim_embed),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.h2y = nn.Sequential(\n",
    "            nn.Linear(dim_embed, 1),\n",
    "            #nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        features = self.main(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = self.x2h_res(features)\n",
    "        out = self.h2y(features)\n",
    "\n",
    "        return out, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18_embed(dim_embed=DIM_EMBED):\n",
    "    return ResNet_embed(BasicBlock, [2,2,2,2], dim_embed=dim_embed)\n",
    "def ResNet34_embed(dim_embed=DIM_EMBED):\n",
    "    return ResNet_embed(BasicBlock, [3,4,6,3], dim_embed=dim_embed)\n",
    "\n",
    "#after testing ResNet18 gives the lowest loss -> better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of CNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "#testing the forward of the network\n",
    "\n",
    "net = ResNet18_embed()\n",
    "\n",
    "img, lab = next(iter(train_loader))\n",
    "out = net(img)\n",
    "\n",
    "print(out[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate_1(optimizer, epoch):\n",
    "        \"\"\"decrease the learning rate \"\"\"\n",
    "        lr = lr_base\n",
    "\n",
    "        num_decays = len(lr_decay_epochs)\n",
    "        for decay_i in range(num_decays):\n",
    "            if epoch >= lr_decay_epochs[decay_i]:\n",
    "                lr = lr * lr_decay_factor\n",
    "            #end if epoch\n",
    "        #end for decay_i\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n4: \n",
      "Train loss: 0.4034976363182068      Test loss: 143919988736.0\n",
      "tensor([[326118.5625],\n",
      "        [280096.0312],\n",
      "        [297693.8750],\n",
      "        [505189.1875],\n",
      "        [343355.1250],\n",
      "        [338734.5625],\n",
      "        [299870.8125],\n",
      "        [339582.5312],\n",
      "        [341441.4688],\n",
      "        [257714.0469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.6944],\n",
      "        [0.5833],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n54: \n",
      "Train loss: 0.11886025965213776      Test loss: 0.09607657790184021\n",
      "tensor([[0.4831],\n",
      "        [0.4909],\n",
      "        [0.4827],\n",
      "        [0.3248],\n",
      "        [0.8695],\n",
      "        [0.8577],\n",
      "        [0.3244],\n",
      "        [0.5726],\n",
      "        [0.5107],\n",
      "        [0.4831]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7500],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n104: \n",
      "Train loss: 0.08259257674217224      Test loss: 0.28496065735816956\n",
      "tensor([[-0.5218],\n",
      "        [-0.7272],\n",
      "        [ 0.3491],\n",
      "        [ 0.3488],\n",
      "        [ 0.3490],\n",
      "        [ 0.3502],\n",
      "        [-0.0365],\n",
      "        [ 0.3489],\n",
      "        [ 0.4052],\n",
      "        [ 0.3487]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.6389],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n154: \n",
      "Train loss: 0.037209466099739075      Test loss: 0.020196788012981415\n",
      "tensor([[0.3521],\n",
      "        [0.5382],\n",
      "        [0.3522],\n",
      "        [0.3657],\n",
      "        [0.3520],\n",
      "        [0.4021],\n",
      "        [0.3521],\n",
      "        [0.5578],\n",
      "        [0.3520],\n",
      "        [0.3832]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4722],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.5556],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n204: \n",
      "Train loss: 0.11266525834798813      Test loss: 0.03259613364934921\n",
      "tensor([[0.2533],\n",
      "        [0.3162],\n",
      "        [0.2896],\n",
      "        [0.1726],\n",
      "        [0.2664],\n",
      "        [0.2733],\n",
      "        [0.2899],\n",
      "        [0.2622],\n",
      "        [0.3457],\n",
      "        [0.2899]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3611],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n254: \n",
      "Train loss: 0.05626295879483223      Test loss: 0.05445956066250801\n",
      "tensor([[ 0.3979],\n",
      "        [ 0.4034],\n",
      "        [ 0.3979],\n",
      "        [ 0.4033],\n",
      "        [-0.0815],\n",
      "        [ 0.3969],\n",
      "        [ 0.4033],\n",
      "        [ 0.3008],\n",
      "        [-0.0124],\n",
      "        [ 0.3363]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.3611],\n",
      "        [0.9167],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.4444],\n",
      "        [0.4722],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n304: \n",
      "Train loss: 0.05501359701156616      Test loss: 0.08719578385353088\n",
      "tensor([[ 0.3351],\n",
      "        [ 0.5065],\n",
      "        [ 0.5067],\n",
      "        [ 0.5088],\n",
      "        [-0.6709],\n",
      "        [ 0.3841],\n",
      "        [ 0.5068],\n",
      "        [ 0.3443],\n",
      "        [ 0.2219],\n",
      "        [ 0.5065]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.2500],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n354: \n",
      "Train loss: 0.07143247127532959      Test loss: 0.041956521570682526\n",
      "tensor([[0.3292],\n",
      "        [0.3324],\n",
      "        [0.3324],\n",
      "        [0.3322],\n",
      "        [0.3320],\n",
      "        [0.3283],\n",
      "        [0.3298],\n",
      "        [0.3322],\n",
      "        [0.3296],\n",
      "        [0.3261]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.4722],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n404: \n",
      "Train loss: 0.0836440920829773      Test loss: 0.02617298811674118\n",
      "tensor([[0.4006],\n",
      "        [0.3998],\n",
      "        [0.3727],\n",
      "        [0.4000],\n",
      "        [0.3033],\n",
      "        [0.1953],\n",
      "        [0.4036],\n",
      "        [0.4000],\n",
      "        [0.4001],\n",
      "        [0.4000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n454: \n",
      "Train loss: 0.05015766620635986      Test loss: 0.2206401228904724\n",
      "tensor([[0.3267],\n",
      "        [0.3545],\n",
      "        [0.3527],\n",
      "        [0.3541],\n",
      "        [0.3545],\n",
      "        [0.3538],\n",
      "        [0.1824],\n",
      "        [0.3545],\n",
      "        [0.3544],\n",
      "        [0.3273]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.9167],\n",
      "        [0.5556],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n504: \n",
      "Train loss: 0.03140672668814659      Test loss: 0.04640377685427666\n",
      "tensor([[0.4924],\n",
      "        [0.4923],\n",
      "        [0.4613],\n",
      "        [0.4410],\n",
      "        [0.2776],\n",
      "        [0.3058],\n",
      "        [0.5050],\n",
      "        [0.5039],\n",
      "        [0.5056],\n",
      "        [0.4914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n554: \n",
      "Train loss: 0.09067124128341675      Test loss: 0.12196538597345352\n",
      "tensor([[ 0.1948],\n",
      "        [ 0.4274],\n",
      "        [ 0.4274],\n",
      "        [-0.2167],\n",
      "        [ 0.4280],\n",
      "        [ 0.3884],\n",
      "        [ 0.4277],\n",
      "        [-0.3629],\n",
      "        [ 0.2682],\n",
      "        [ 0.4274]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5000],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.5278]], device='cuda:0')\n",
      "epoch n604: \n",
      "Train loss: 0.07958278059959412      Test loss: 0.01918170228600502\n",
      "tensor([[0.3984],\n",
      "        [0.3866],\n",
      "        [0.3598],\n",
      "        [0.3583],\n",
      "        [0.3607],\n",
      "        [0.3924],\n",
      "        [0.3598],\n",
      "        [0.4084],\n",
      "        [0.4426],\n",
      "        [0.3479]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n654: \n",
      "Train loss: 0.039000801742076874      Test loss: 0.03422516584396362\n",
      "tensor([[0.3589],\n",
      "        [0.3598],\n",
      "        [0.3594],\n",
      "        [0.3594],\n",
      "        [0.3582],\n",
      "        [0.2711],\n",
      "        [0.2871],\n",
      "        [0.3973],\n",
      "        [0.3578],\n",
      "        [0.3596]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9167],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n704: \n",
      "Train loss: 0.07826045900583267      Test loss: 0.0371396578848362\n",
      "tensor([[0.4800],\n",
      "        [0.4724],\n",
      "        [0.4395],\n",
      "        [0.4400],\n",
      "        [0.4882],\n",
      "        [0.4397],\n",
      "        [0.4393],\n",
      "        [0.4381],\n",
      "        [0.4381],\n",
      "        [0.5207]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n754: \n",
      "Train loss: 0.052729833871126175      Test loss: 0.04398781806230545\n",
      "tensor([[ 0.3656],\n",
      "        [ 0.3649],\n",
      "        [ 0.3651],\n",
      "        [ 0.3533],\n",
      "        [ 0.3651],\n",
      "        [ 0.3564],\n",
      "        [ 0.3652],\n",
      "        [-0.0412],\n",
      "        [ 0.3649],\n",
      "        [ 0.3658]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n804: \n",
      "Train loss: 0.09614097326993942      Test loss: 0.10856997221708298\n",
      "tensor([[0.3672],\n",
      "        [0.3686],\n",
      "        [0.6772],\n",
      "        [0.4371],\n",
      "        [0.3669],\n",
      "        [0.3666],\n",
      "        [0.3664],\n",
      "        [0.3674],\n",
      "        [0.3671],\n",
      "        [0.3672]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.8889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n854: \n",
      "Train loss: 0.05222364515066147      Test loss: 0.03891918808221817\n",
      "tensor([[0.3223],\n",
      "        [0.3229],\n",
      "        [0.3587],\n",
      "        [0.3354],\n",
      "        [0.3662],\n",
      "        [0.3611],\n",
      "        [0.3776],\n",
      "        [0.3231],\n",
      "        [0.3230],\n",
      "        [0.3701]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.0278],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n904: \n",
      "Train loss: 0.06952294707298279      Test loss: 0.08554230630397797\n",
      "tensor([[ 0.3727],\n",
      "        [ 0.3659],\n",
      "        [ 0.3685],\n",
      "        [ 0.0150],\n",
      "        [ 0.3660],\n",
      "        [ 0.2327],\n",
      "        [ 0.3661],\n",
      "        [-0.2458],\n",
      "        [ 0.3937],\n",
      "        [ 0.3671]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.7500],\n",
      "        [0.3611],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n954: \n",
      "Train loss: 0.06512288749217987      Test loss: 0.02707827277481556\n",
      "tensor([[0.3589],\n",
      "        [0.3585],\n",
      "        [0.3607],\n",
      "        [0.3585],\n",
      "        [0.3578],\n",
      "        [0.3580],\n",
      "        [0.3483],\n",
      "        [0.3581],\n",
      "        [0.3581],\n",
      "        [0.3977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n1004: \n",
      "Train loss: 0.026886356994509697      Test loss: 0.01750255934894085\n",
      "tensor([[0.4491],\n",
      "        [0.4480],\n",
      "        [0.4239],\n",
      "        [0.4476],\n",
      "        [0.4869],\n",
      "        [0.4476],\n",
      "        [0.4476],\n",
      "        [0.4478],\n",
      "        [0.5432],\n",
      "        [0.4477]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.2500],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.9444],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n1054: \n",
      "Train loss: 0.0564531609416008      Test loss: 0.035368360579013824\n",
      "tensor([[0.4460],\n",
      "        [0.4459],\n",
      "        [0.4825],\n",
      "        [0.4450],\n",
      "        [0.4450],\n",
      "        [0.4651],\n",
      "        [0.4461],\n",
      "        [0.4507],\n",
      "        [0.4696],\n",
      "        [0.4704]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n1104: \n",
      "Train loss: 0.04092521220445633      Test loss: 0.04199298471212387\n",
      "tensor([[0.3684],\n",
      "        [0.3684],\n",
      "        [0.2693],\n",
      "        [0.3685],\n",
      "        [0.3683],\n",
      "        [0.3685],\n",
      "        [0.3685],\n",
      "        [0.3740],\n",
      "        [0.3675],\n",
      "        [0.3684]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.9167]], device='cuda:0')\n",
      "epoch n1154: \n",
      "Train loss: 0.05332683026790619      Test loss: 0.04065673053264618\n",
      "tensor([[0.3905],\n",
      "        [0.3817],\n",
      "        [0.4453],\n",
      "        [0.8850],\n",
      "        [0.3791],\n",
      "        [0.8731],\n",
      "        [0.3790],\n",
      "        [0.3975],\n",
      "        [0.3796],\n",
      "        [0.3796]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.7500],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n1204: \n",
      "Train loss: 0.03210735321044922      Test loss: 0.018070343881845474\n",
      "tensor([[0.3794],\n",
      "        [0.3793],\n",
      "        [0.3841],\n",
      "        [0.3838],\n",
      "        [0.3848],\n",
      "        [0.3790],\n",
      "        [0.3973],\n",
      "        [0.3779],\n",
      "        [0.3787],\n",
      "        [0.3816]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.6111],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n1254: \n",
      "Train loss: 0.046187013387680054      Test loss: 0.04311433434486389\n",
      "tensor([[0.4032],\n",
      "        [0.4031],\n",
      "        [0.3161],\n",
      "        [0.4037],\n",
      "        [0.4034],\n",
      "        [0.4003],\n",
      "        [0.4033],\n",
      "        [0.4037],\n",
      "        [0.4028],\n",
      "        [0.2469]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n1304: \n",
      "Train loss: 0.038660697638988495      Test loss: 0.02517792209982872\n",
      "tensor([[0.4265],\n",
      "        [0.4864],\n",
      "        [0.3956],\n",
      "        [0.3959],\n",
      "        [0.3952],\n",
      "        [0.3959],\n",
      "        [0.3957],\n",
      "        [0.3958],\n",
      "        [0.4767],\n",
      "        [0.4303]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.7500],\n",
      "        [0.4167],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n1354: \n",
      "Train loss: 0.03732677176594734      Test loss: 0.02418084442615509\n",
      "tensor([[0.3628],\n",
      "        [0.3628],\n",
      "        [0.3624],\n",
      "        [0.3621],\n",
      "        [0.3628],\n",
      "        [0.3619],\n",
      "        [0.3612],\n",
      "        [0.3622],\n",
      "        [0.3626],\n",
      "        [0.3627]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.6389],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n1404: \n",
      "Train loss: 0.06600505113601685      Test loss: 0.023172002285718918\n",
      "tensor([[0.4440],\n",
      "        [0.4388],\n",
      "        [0.4388],\n",
      "        [0.4406],\n",
      "        [0.4408],\n",
      "        [0.4406],\n",
      "        [0.5042],\n",
      "        [0.4411],\n",
      "        [0.4410],\n",
      "        [0.4408]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n1454: \n",
      "Train loss: 0.05585581064224243      Test loss: 0.02382909692823887\n",
      "tensor([[0.3386],\n",
      "        [0.3385],\n",
      "        [0.3472],\n",
      "        [0.3512],\n",
      "        [0.3392],\n",
      "        [0.3484],\n",
      "        [0.3483],\n",
      "        [0.3398],\n",
      "        [0.3474],\n",
      "        [0.3483]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.0278],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n1504: \n",
      "Train loss: 0.07206372916698456      Test loss: 0.01585441455245018\n",
      "tensor([[0.4053],\n",
      "        [0.4042],\n",
      "        [0.4070],\n",
      "        [0.4063],\n",
      "        [0.4073],\n",
      "        [0.4072],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4073],\n",
      "        [0.4274]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n1554: \n",
      "Train loss: 0.03300117701292038      Test loss: 0.02631211094558239\n",
      "tensor([[0.3657],\n",
      "        [0.3658],\n",
      "        [0.4636],\n",
      "        [0.3664],\n",
      "        [0.3659],\n",
      "        [0.3667],\n",
      "        [0.3661],\n",
      "        [0.3659],\n",
      "        [0.3662],\n",
      "        [0.3663]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n1604: \n",
      "Train loss: 0.07786455750465393      Test loss: 0.01973697543144226\n",
      "tensor([[0.4139],\n",
      "        [0.4135],\n",
      "        [0.4349],\n",
      "        [0.4105],\n",
      "        [0.4100],\n",
      "        [0.4140],\n",
      "        [0.4139],\n",
      "        [0.4100],\n",
      "        [0.4136],\n",
      "        [0.4140]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.7222],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n1654: \n",
      "Train loss: 0.04939718544483185      Test loss: 0.02477826178073883\n",
      "tensor([[0.3539],\n",
      "        [0.3736],\n",
      "        [0.3736],\n",
      "        [0.3736],\n",
      "        [0.3735],\n",
      "        [0.3736],\n",
      "        [0.3502],\n",
      "        [0.3732],\n",
      "        [0.3741],\n",
      "        [0.3737]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.3333],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n1704: \n",
      "Train loss: 0.06593582779169083      Test loss: 0.019799524918198586\n",
      "tensor([[0.5427],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.5057],\n",
      "        [0.4022],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4018],\n",
      "        [0.4021]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.7222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4444]], device='cuda:0')\n",
      "epoch n1754: \n",
      "Train loss: 0.02991444244980812      Test loss: 0.027813225984573364\n",
      "tensor([[0.3637],\n",
      "        [0.3637],\n",
      "        [0.3638],\n",
      "        [0.3639],\n",
      "        [0.3638],\n",
      "        [0.3638],\n",
      "        [0.3638],\n",
      "        [0.3637],\n",
      "        [0.3638],\n",
      "        [0.3700]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5278],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.4444]], device='cuda:0')\n",
      "epoch n1804: \n",
      "Train loss: 0.09931144118309021      Test loss: 0.040107447654008865\n",
      "tensor([[0.3885],\n",
      "        [0.3886],\n",
      "        [0.3901],\n",
      "        [0.3884],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3884],\n",
      "        [0.3887],\n",
      "        [0.3899],\n",
      "        [0.3884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n1854: \n",
      "Train loss: 0.03190409392118454      Test loss: 0.06155206635594368\n",
      "tensor([[0.4179],\n",
      "        [0.4266],\n",
      "        [0.4184],\n",
      "        [0.4176],\n",
      "        [0.4185],\n",
      "        [0.4180],\n",
      "        [0.4173],\n",
      "        [0.4183],\n",
      "        [0.7471],\n",
      "        [0.4183]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6389],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n1904: \n",
      "Train loss: 0.030412647873163223      Test loss: 0.03508889302611351\n",
      "tensor([[0.3751],\n",
      "        [0.3923],\n",
      "        [0.3923],\n",
      "        [0.3924],\n",
      "        [0.3926],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3907],\n",
      "        [0.3924],\n",
      "        [0.3924]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n1954: \n",
      "Train loss: 0.021345775574445724      Test loss: 0.04793151468038559\n",
      "tensor([[0.4188],\n",
      "        [0.3802],\n",
      "        [0.3791],\n",
      "        [0.3805],\n",
      "        [0.3803],\n",
      "        [0.3835],\n",
      "        [0.3802],\n",
      "        [0.3801],\n",
      "        [0.3791],\n",
      "        [0.3863]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9444],\n",
      "        [0.5556],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.4722],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n2004: \n",
      "Train loss: 0.049020975828170776      Test loss: 0.0257270447909832\n",
      "tensor([[0.4166],\n",
      "        [0.4176],\n",
      "        [0.4902],\n",
      "        [0.4175],\n",
      "        [0.4292],\n",
      "        [0.4175],\n",
      "        [0.4166],\n",
      "        [0.4175],\n",
      "        [0.4175],\n",
      "        [0.6129]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n2054: \n",
      "Train loss: 0.019757727161049843      Test loss: 0.05335956811904907\n",
      "tensor([[0.3506],\n",
      "        [0.3506],\n",
      "        [0.3507],\n",
      "        [0.3506],\n",
      "        [0.3506],\n",
      "        [0.3507],\n",
      "        [0.3506],\n",
      "        [0.3509],\n",
      "        [0.3506],\n",
      "        [0.3506]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3611],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n2104: \n",
      "Train loss: 0.018741082400083542      Test loss: 0.016587233170866966\n",
      "tensor([[0.3916],\n",
      "        [0.4060],\n",
      "        [0.3926],\n",
      "        [0.3919],\n",
      "        [0.3917],\n",
      "        [0.3919],\n",
      "        [0.3918],\n",
      "        [0.3898],\n",
      "        [0.3917],\n",
      "        [0.3917]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3611],\n",
      "        [0.4722],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n2154: \n",
      "Train loss: 0.05226627737283707      Test loss: 0.04305705800652504\n",
      "tensor([[0.3856],\n",
      "        [0.3857],\n",
      "        [0.3858],\n",
      "        [0.3858],\n",
      "        [0.3857],\n",
      "        [0.3857],\n",
      "        [0.3856],\n",
      "        [0.3858],\n",
      "        [0.3870],\n",
      "        [0.3860]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7500],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.9167]], device='cuda:0')\n",
      "epoch n2204: \n",
      "Train loss: 0.06685327738523483      Test loss: 0.02433263137936592\n",
      "tensor([[0.3800],\n",
      "        [0.3801],\n",
      "        [0.3802],\n",
      "        [0.3811],\n",
      "        [0.3801],\n",
      "        [0.3800],\n",
      "        [0.3801],\n",
      "        [0.3728],\n",
      "        [0.3802],\n",
      "        [0.3824]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5278],\n",
      "        [0.3611],\n",
      "        [0.2778],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n2254: \n",
      "Train loss: 0.029085399582982063      Test loss: 0.02919270657002926\n",
      "tensor([[0.5544],\n",
      "        [0.3818],\n",
      "        [0.5050],\n",
      "        [0.3818],\n",
      "        [0.3818],\n",
      "        [0.3818],\n",
      "        [0.3974],\n",
      "        [0.3818],\n",
      "        [0.3818],\n",
      "        [0.3818]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n2304: \n",
      "Train loss: 0.025279980152845383      Test loss: 0.03303506597876549\n",
      "tensor([[0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066],\n",
      "        [0.4066]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n2354: \n",
      "Train loss: 0.02320105955004692      Test loss: 0.024139171466231346\n",
      "tensor([[0.3901],\n",
      "        [0.4102],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901],\n",
      "        [0.3901]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n2404: \n",
      "Train loss: 0.04794915392994881      Test loss: 0.02089867740869522\n",
      "tensor([[0.3924],\n",
      "        [0.3912],\n",
      "        [0.3912],\n",
      "        [0.3912],\n",
      "        [0.4071],\n",
      "        [0.3912],\n",
      "        [0.3912],\n",
      "        [0.4178],\n",
      "        [0.3912],\n",
      "        [0.3912]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n2454: \n",
      "Train loss: 0.044611718505620956      Test loss: 0.02399197593331337\n",
      "tensor([[0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.5281],\n",
      "        [0.4010]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5278],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n2504: \n",
      "Train loss: 0.048710014671087265      Test loss: 0.03240342438220978\n",
      "tensor([[0.3755],\n",
      "        [0.3755],\n",
      "        [0.6011],\n",
      "        [0.3755],\n",
      "        [0.3755],\n",
      "        [0.4422],\n",
      "        [0.3755],\n",
      "        [0.3755],\n",
      "        [0.5468],\n",
      "        [0.3755]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n2554: \n",
      "Train loss: 0.06338189542293549      Test loss: 0.01731337234377861\n",
      "tensor([[0.4122],\n",
      "        [0.4133],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4122],\n",
      "        [0.4179]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n2604: \n",
      "Train loss: 0.06655000150203705      Test loss: 0.03972167149186134\n",
      "tensor([[0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3642],\n",
      "        [0.3693],\n",
      "        [0.3642]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.6944],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.2500],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n2654: \n",
      "Train loss: 0.06805990636348724      Test loss: 0.03010532259941101\n",
      "tensor([[0.7015],\n",
      "        [0.3956],\n",
      "        [0.4735],\n",
      "        [0.3953],\n",
      "        [0.5024],\n",
      "        [0.4124],\n",
      "        [0.4166],\n",
      "        [0.3953],\n",
      "        [0.3953],\n",
      "        [0.3953]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n2704: \n",
      "Train loss: 0.01783861592411995      Test loss: 0.027440913021564484\n",
      "tensor([[0.3970],\n",
      "        [0.3898],\n",
      "        [0.3898],\n",
      "        [0.3898],\n",
      "        [0.4269],\n",
      "        [0.3898],\n",
      "        [0.3898],\n",
      "        [0.3898],\n",
      "        [0.3898],\n",
      "        [0.3898]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n2754: \n",
      "Train loss: 0.07240134477615356      Test loss: 0.02474193274974823\n",
      "tensor([[0.3794],\n",
      "        [0.3794],\n",
      "        [0.3794],\n",
      "        [0.5469],\n",
      "        [0.3794],\n",
      "        [0.3794],\n",
      "        [0.3794],\n",
      "        [0.3794],\n",
      "        [0.3794],\n",
      "        [0.3794]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.4444]], device='cuda:0')\n",
      "epoch n2804: \n",
      "Train loss: 0.07470478117465973      Test loss: 0.02616245113313198\n",
      "tensor([[0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006],\n",
      "        [0.4006]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.6389],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n2854: \n",
      "Train loss: 0.04254109784960747      Test loss: 0.017804697155952454\n",
      "tensor([[0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.4189],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.4444],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n2904: \n",
      "Train loss: 0.0653693675994873      Test loss: 0.041230589151382446\n",
      "tensor([[0.4198],\n",
      "        [0.5617],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.5212],\n",
      "        [0.3925],\n",
      "        [0.4197],\n",
      "        [0.4259],\n",
      "        [0.3925],\n",
      "        [0.4037]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0278],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.9444],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n2954: \n",
      "Train loss: 0.029742199927568436      Test loss: 0.056183136999607086\n",
      "tensor([[0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3901],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3905]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.0278],\n",
      "        [0.9444],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n3004: \n",
      "Train loss: 0.05028562992811203      Test loss: 0.01294583547860384\n",
      "tensor([[0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4137],\n",
      "        [0.4062],\n",
      "        [0.4062]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n3054: \n",
      "Train loss: 0.05937008559703827      Test loss: 0.03284703567624092\n",
      "tensor([[0.3808],\n",
      "        [0.3806],\n",
      "        [0.3910],\n",
      "        [0.4294],\n",
      "        [0.3806],\n",
      "        [0.3806],\n",
      "        [0.3814],\n",
      "        [0.3814],\n",
      "        [0.3806],\n",
      "        [0.3814]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n3104: \n",
      "Train loss: 0.07822044938802719      Test loss: 0.01993732526898384\n",
      "tensor([[0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3861],\n",
      "        [0.3883]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.6944],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n3154: \n",
      "Train loss: 0.07248502969741821      Test loss: 0.031110284850001335\n",
      "tensor([[0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.4039],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.6389],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5278],\n",
      "        [0.2222],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n3204: \n",
      "Train loss: 0.04978739470243454      Test loss: 0.01447678729891777\n",
      "tensor([[0.3464],\n",
      "        [0.3464],\n",
      "        [0.3464],\n",
      "        [0.3464],\n",
      "        [0.3464],\n",
      "        [0.3464],\n",
      "        [0.3464],\n",
      "        [0.3886],\n",
      "        [0.3464],\n",
      "        [0.3464]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.2500],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n3254: \n",
      "Train loss: 0.0740145891904831      Test loss: 0.01375984400510788\n",
      "tensor([[0.3799],\n",
      "        [0.3799],\n",
      "        [0.5300],\n",
      "        [0.3799],\n",
      "        [0.3799],\n",
      "        [0.3799],\n",
      "        [0.3799],\n",
      "        [0.3799],\n",
      "        [0.4312],\n",
      "        [0.6374]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.5278],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n3304: \n",
      "Train loss: 0.04886358231306076      Test loss: 0.019134018570184708\n",
      "tensor([[0.4003],\n",
      "        [0.4003],\n",
      "        [0.4003],\n",
      "        [0.4080],\n",
      "        [0.4003],\n",
      "        [0.4003],\n",
      "        [0.4003],\n",
      "        [0.4939],\n",
      "        [0.4003],\n",
      "        [0.4003]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n3354: \n",
      "Train loss: 0.03592004254460335      Test loss: 0.020118754357099533\n",
      "tensor([[0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138],\n",
      "        [0.4138]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n3404: \n",
      "Train loss: 0.03913833573460579      Test loss: 0.03580786660313606\n",
      "tensor([[0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503],\n",
      "        [0.3503]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n3454: \n",
      "Train loss: 0.028350243344902992      Test loss: 0.036752067506313324\n",
      "tensor([[0.3883],\n",
      "        [0.3883],\n",
      "        [0.3910],\n",
      "        [0.3883],\n",
      "        [0.3883],\n",
      "        [0.3883],\n",
      "        [0.3883],\n",
      "        [0.3883],\n",
      "        [0.4068],\n",
      "        [0.3883]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.4722],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n3504: \n",
      "Train loss: 0.05053473636507988      Test loss: 0.030369557440280914\n",
      "tensor([[0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3889],\n",
      "        [0.3886],\n",
      "        [0.5639],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.4452]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.1389],\n",
      "        [0.0833],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n3554: \n",
      "Train loss: 0.0474560409784317      Test loss: 0.01843280717730522\n",
      "tensor([[0.4383],\n",
      "        [0.4383],\n",
      "        [0.4383],\n",
      "        [0.5278],\n",
      "        [0.4383],\n",
      "        [0.4383],\n",
      "        [0.4714],\n",
      "        [0.4383],\n",
      "        [0.4383],\n",
      "        [0.4383]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7500],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n3604: \n",
      "Train loss: 0.03944327309727669      Test loss: 0.020687133073806763\n",
      "tensor([[0.3921],\n",
      "        [0.4663],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3956]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n3654: \n",
      "Train loss: 0.07781626284122467      Test loss: 0.02921188436448574\n",
      "tensor([[0.4628],\n",
      "        [0.3742],\n",
      "        [0.3725],\n",
      "        [0.3725],\n",
      "        [0.3958],\n",
      "        [0.3725],\n",
      "        [0.4763],\n",
      "        [0.4246],\n",
      "        [0.4072],\n",
      "        [0.3855]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.7500],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n3704: \n",
      "Train loss: 0.03385128825902939      Test loss: 0.026211457327008247\n",
      "tensor([[0.4056],\n",
      "        [0.4056],\n",
      "        [0.4080],\n",
      "        [0.4056],\n",
      "        [0.4072],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4217],\n",
      "        [0.4113],\n",
      "        [0.4056]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.6389],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n3754: \n",
      "Train loss: 0.03029080107808113      Test loss: 0.015106250531971455\n",
      "tensor([[0.3691],\n",
      "        [0.3640],\n",
      "        [0.3643],\n",
      "        [0.3624],\n",
      "        [0.3658],\n",
      "        [0.3731],\n",
      "        [0.3673],\n",
      "        [0.3798],\n",
      "        [0.3642],\n",
      "        [0.3643]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n3804: \n",
      "Train loss: 0.10661856085062027      Test loss: 0.021352821961045265\n",
      "tensor([[0.4196],\n",
      "        [0.4170],\n",
      "        [0.4160],\n",
      "        [0.4168],\n",
      "        [0.4304],\n",
      "        [0.4172],\n",
      "        [0.4180],\n",
      "        [0.4156],\n",
      "        [0.4225],\n",
      "        [0.4172]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5556],\n",
      "        [0.4444],\n",
      "        [0.1944],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n3854: \n",
      "Train loss: 0.04051076993346214      Test loss: 0.03455887734889984\n",
      "tensor([[0.3905],\n",
      "        [0.3906],\n",
      "        [0.3941],\n",
      "        [0.3905],\n",
      "        [0.3905],\n",
      "        [0.4092],\n",
      "        [0.4354],\n",
      "        [0.3905],\n",
      "        [0.3905],\n",
      "        [0.3905]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n3904: \n",
      "Train loss: 0.04382966458797455      Test loss: 0.028569310903549194\n",
      "tensor([[0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.4237],\n",
      "        [0.4126],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.7222],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.6111],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n3954: \n",
      "Train loss: 0.05448925495147705      Test loss: 0.02176450565457344\n",
      "tensor([[0.3692],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687],\n",
      "        [0.3687]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4722],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.5278],\n",
      "        [0.3889],\n",
      "        [0.2500],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n4004: \n",
      "Train loss: 0.042799148708581924      Test loss: 0.021460989490151405\n",
      "tensor([[0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4071],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4062],\n",
      "        [0.4065],\n",
      "        [0.4062]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n4054: \n",
      "Train loss: 0.07408975809812546      Test loss: 0.031246243044734\n",
      "tensor([[0.4113],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032],\n",
      "        [0.4032]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.7500],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n4104: \n",
      "Train loss: 0.052289579063653946      Test loss: 0.0265004001557827\n",
      "tensor([[0.3919],\n",
      "        [0.4210],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3925],\n",
      "        [0.3919],\n",
      "        [0.5163]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.0278],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n4154: \n",
      "Train loss: 0.049385685473680496      Test loss: 0.02564937248826027\n",
      "tensor([[0.3398],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404],\n",
      "        [0.3404]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3889],\n",
      "        [0.1944],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n4204: \n",
      "Train loss: 0.07458692789077759      Test loss: 0.029409274458885193\n",
      "tensor([[0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658],\n",
      "        [0.3658]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5278],\n",
      "        [0.2778],\n",
      "        [0.7222],\n",
      "        [0.4722],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n4254: \n",
      "Train loss: 0.06231331825256348      Test loss: 0.02859794721007347\n",
      "tensor([[0.4035],\n",
      "        [0.4035],\n",
      "        [0.4035],\n",
      "        [0.4035],\n",
      "        [0.4035],\n",
      "        [0.4509],\n",
      "        [0.4035],\n",
      "        [0.4035],\n",
      "        [0.4035],\n",
      "        [0.4035]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.3611],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n4304: \n",
      "Train loss: 0.039649300277233124      Test loss: 0.029380302876234055\n",
      "tensor([[0.3988],\n",
      "        [0.3879],\n",
      "        [0.3583],\n",
      "        [0.3738],\n",
      "        [0.3748],\n",
      "        [0.3746],\n",
      "        [0.3716],\n",
      "        [0.3879],\n",
      "        [0.3576],\n",
      "        [0.3509]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.1389],\n",
      "        [0.5833],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n4354: \n",
      "Train loss: 0.04453224688768387      Test loss: 0.05252702534198761\n",
      "tensor([[0.3922],\n",
      "        [0.4086],\n",
      "        [0.4021],\n",
      "        [0.4089],\n",
      "        [0.4041],\n",
      "        [0.4127],\n",
      "        [0.4106],\n",
      "        [0.3961],\n",
      "        [0.4103],\n",
      "        [0.4049]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9444],\n",
      "        [0.8889],\n",
      "        [0.6389],\n",
      "        [0.6944],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n4404: \n",
      "Train loss: 0.022527921944856644      Test loss: 0.03407026827335358\n",
      "tensor([[0.4193],\n",
      "        [0.4278],\n",
      "        [0.4191],\n",
      "        [0.7408],\n",
      "        [0.4248],\n",
      "        [0.4313],\n",
      "        [0.4197],\n",
      "        [0.5855],\n",
      "        [0.4316],\n",
      "        [0.4301]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n4454: \n",
      "Train loss: 0.0433836504817009      Test loss: 0.01983584091067314\n",
      "tensor([[0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910],\n",
      "        [0.3910]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n4504: \n",
      "Train loss: 0.06902863085269928      Test loss: 0.027093321084976196\n",
      "tensor([[0.3406],\n",
      "        [0.3406],\n",
      "        [0.3406],\n",
      "        [0.3544],\n",
      "        [0.3406],\n",
      "        [0.3891],\n",
      "        [0.3406],\n",
      "        [0.3406],\n",
      "        [0.3406],\n",
      "        [0.3406]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.0833],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n4554: \n",
      "Train loss: 0.04241340234875679      Test loss: 0.03859684616327286\n",
      "tensor([[0.3509],\n",
      "        [0.3509],\n",
      "        [0.3556],\n",
      "        [0.3509],\n",
      "        [0.3509],\n",
      "        [0.3522],\n",
      "        [0.3509],\n",
      "        [0.3853],\n",
      "        [0.3509],\n",
      "        [0.3509]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n4604: \n",
      "Train loss: 0.03363842889666557      Test loss: 0.02399061992764473\n",
      "tensor([[0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262],\n",
      "        [0.4262]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6389],\n",
      "        [0.5278],\n",
      "        [0.4167],\n",
      "        [0.6389],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n4654: \n",
      "Train loss: 0.07937882095575333      Test loss: 0.04113983362913132\n",
      "tensor([[0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3888],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n4704: \n",
      "Train loss: 0.04226909577846527      Test loss: 0.04666735976934433\n",
      "tensor([[0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251],\n",
      "        [0.4251]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.8889],\n",
      "        [0.3056],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n4754: \n",
      "Train loss: 0.022574426606297493      Test loss: 0.03280012682080269\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.4118]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.7222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.7500],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n4804: \n",
      "Train loss: 0.037349436432123184      Test loss: 0.0206315815448761\n",
      "tensor([[0.4238],\n",
      "        [0.4650],\n",
      "        [0.4235],\n",
      "        [0.4153],\n",
      "        [0.4153],\n",
      "        [0.4153],\n",
      "        [0.4153],\n",
      "        [0.4153],\n",
      "        [0.4153],\n",
      "        [0.4153]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0278],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.4167],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n4854: \n",
      "Train loss: 0.0996221974492073      Test loss: 0.05056426674127579\n",
      "tensor([[0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9167],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.2778],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.0278],\n",
      "        [0.8889],\n",
      "        [0.4167],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n4904: \n",
      "Train loss: 0.06091007590293884      Test loss: 0.0389079786837101\n",
      "tensor([[0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.4415],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n4954: \n",
      "Train loss: 0.041453100740909576      Test loss: 0.02531721629202366\n",
      "tensor([[0.4035],\n",
      "        [0.4002],\n",
      "        [0.4311],\n",
      "        [0.4002],\n",
      "        [0.4613],\n",
      "        [0.4002],\n",
      "        [0.4002],\n",
      "        [0.4002],\n",
      "        [0.4002],\n",
      "        [0.4002]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.6389],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n5004: \n",
      "Train loss: 0.032732345163822174      Test loss: 0.04470685124397278\n",
      "tensor([[0.4725],\n",
      "        [0.3911],\n",
      "        [0.4494],\n",
      "        [0.3797],\n",
      "        [0.3797],\n",
      "        [0.3797],\n",
      "        [0.3797],\n",
      "        [0.3797],\n",
      "        [0.4221],\n",
      "        [0.3797]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5278],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.0278],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n5054: \n",
      "Train loss: 0.05196509510278702      Test loss: 0.03406453877687454\n",
      "tensor([[0.3924],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.4130],\n",
      "        [0.3924],\n",
      "        [0.3924],\n",
      "        [0.3924]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.9167],\n",
      "        [0.4722],\n",
      "        [0.5278],\n",
      "        [0.3333],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n5104: \n",
      "Train loss: 0.09387043118476868      Test loss: 0.031791962683200836\n",
      "tensor([[0.4005],\n",
      "        [0.4005],\n",
      "        [0.4005],\n",
      "        [0.4005],\n",
      "        [0.4137],\n",
      "        [0.4005],\n",
      "        [0.4005],\n",
      "        [0.4005],\n",
      "        [0.4005],\n",
      "        [0.4005]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.2222],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n5154: \n",
      "Train loss: 0.031988725066185      Test loss: 0.03098837099969387\n",
      "tensor([[0.3436],\n",
      "        [0.3436],\n",
      "        [0.3436],\n",
      "        [0.3436],\n",
      "        [0.3436],\n",
      "        [0.3436],\n",
      "        [0.3492],\n",
      "        [0.3436],\n",
      "        [0.3436],\n",
      "        [0.3436]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n5204: \n",
      "Train loss: 0.0533757247030735      Test loss: 0.021168548613786697\n",
      "tensor([[0.4088],\n",
      "        [0.4165],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4081]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.2778],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n5254: \n",
      "Train loss: 0.03223313018679619      Test loss: 0.029307588934898376\n",
      "tensor([[0.4048],\n",
      "        [0.4048],\n",
      "        [0.4101],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.7222],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.4444],\n",
      "        [0.6389],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n5304: \n",
      "Train loss: 0.05860862508416176      Test loss: 0.025765400379896164\n",
      "tensor([[0.3709],\n",
      "        [0.3709],\n",
      "        [0.3709],\n",
      "        [0.3709],\n",
      "        [0.3709],\n",
      "        [0.3709],\n",
      "        [0.3747],\n",
      "        [0.3709],\n",
      "        [0.3709],\n",
      "        [0.3709]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3611],\n",
      "        [0.5000],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n5354: \n",
      "Train loss: 0.06810431182384491      Test loss: 0.028729885816574097\n",
      "tensor([[0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169],\n",
      "        [0.4169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.9167],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n5404: \n",
      "Train loss: 0.07692453265190125      Test loss: 0.02957047149538994\n",
      "tensor([[0.5140],\n",
      "        [0.4074],\n",
      "        [0.4074],\n",
      "        [0.4074],\n",
      "        [0.4074],\n",
      "        [0.4074],\n",
      "        [0.4561],\n",
      "        [0.4074],\n",
      "        [0.4074],\n",
      "        [0.4074]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n5454: \n",
      "Train loss: 0.0820196121931076      Test loss: 0.03133116662502289\n",
      "tensor([[0.3769],\n",
      "        [0.3769],\n",
      "        [0.3769],\n",
      "        [0.3769],\n",
      "        [0.3769],\n",
      "        [0.3800],\n",
      "        [0.3769],\n",
      "        [0.3769],\n",
      "        [0.3769],\n",
      "        [0.3764]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n5504: \n",
      "Train loss: 0.04645759239792824      Test loss: 0.02136847749352455\n",
      "tensor([[0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037],\n",
      "        [0.4037]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n5554: \n",
      "Train loss: 0.046651411801576614      Test loss: 0.031107984483242035\n",
      "tensor([[0.3936],\n",
      "        [0.3770],\n",
      "        [0.3770],\n",
      "        [0.3770],\n",
      "        [0.3770],\n",
      "        [0.3764],\n",
      "        [0.3770],\n",
      "        [0.3770],\n",
      "        [0.3770],\n",
      "        [0.3770]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.7500],\n",
      "        [0.2778],\n",
      "        [0.4444],\n",
      "        [0.4167],\n",
      "        [0.6389],\n",
      "        [0.6944],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n5604: \n",
      "Train loss: 0.04264125972986221      Test loss: 0.02351083606481552\n",
      "tensor([[0.3811],\n",
      "        [0.3811],\n",
      "        [0.3811],\n",
      "        [0.3811],\n",
      "        [0.3811],\n",
      "        [0.3811],\n",
      "        [0.3811],\n",
      "        [0.4354],\n",
      "        [0.3811],\n",
      "        [0.3811]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3611],\n",
      "        [0.4722],\n",
      "        [0.2778],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n5654: \n",
      "Train loss: 0.03447182849049568      Test loss: 0.03262871131300926\n",
      "tensor([[0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.6944],\n",
      "        [0.0278]], device='cuda:0')\n",
      "epoch n5704: \n",
      "Train loss: 0.016644448041915894      Test loss: 0.019398082047700882\n",
      "tensor([[0.4208],\n",
      "        [0.4208],\n",
      "        [0.4208],\n",
      "        [0.5204],\n",
      "        [0.4208],\n",
      "        [0.4791],\n",
      "        [0.4208],\n",
      "        [0.4208],\n",
      "        [0.4208],\n",
      "        [0.4208]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n5754: \n",
      "Train loss: 0.05104375258088112      Test loss: 0.02546520344913006\n",
      "tensor([[0.4203],\n",
      "        [0.4203],\n",
      "        [0.4203],\n",
      "        [0.4203],\n",
      "        [0.4429],\n",
      "        [0.4203],\n",
      "        [0.4203],\n",
      "        [0.4203],\n",
      "        [0.4245],\n",
      "        [0.4291]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.0278]], device='cuda:0')\n",
      "epoch n5804: \n",
      "Train loss: 0.11798445880413055      Test loss: 0.02256568893790245\n",
      "tensor([[0.3680],\n",
      "        [0.3860],\n",
      "        [0.3656],\n",
      "        [0.3656],\n",
      "        [0.3886],\n",
      "        [0.3656],\n",
      "        [0.3656],\n",
      "        [0.3656],\n",
      "        [0.3656],\n",
      "        [0.3656]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n5854: \n",
      "Train loss: 0.03592298924922943      Test loss: 0.022293033078312874\n",
      "tensor([[0.3804],\n",
      "        [0.3804],\n",
      "        [0.3894],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.4768],\n",
      "        [0.3804],\n",
      "        [0.3804]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n5904: \n",
      "Train loss: 0.04008496552705765      Test loss: 0.025311294943094254\n",
      "tensor([[0.3893],\n",
      "        [0.4309],\n",
      "        [0.3893],\n",
      "        [0.3958],\n",
      "        [0.3893],\n",
      "        [0.3893],\n",
      "        [0.3893],\n",
      "        [0.3993],\n",
      "        [0.3893],\n",
      "        [0.3893]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n5954: \n",
      "Train loss: 0.12233082950115204      Test loss: 0.04992640018463135\n",
      "tensor([[0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051],\n",
      "        [0.4051]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.7222],\n",
      "        [0.5833],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n6004: \n",
      "Train loss: 0.03432689607143402      Test loss: 0.02516384981572628\n",
      "tensor([[0.5727],\n",
      "        [0.3824],\n",
      "        [0.4001],\n",
      "        [0.3824],\n",
      "        [0.3824],\n",
      "        [0.3824],\n",
      "        [0.3824],\n",
      "        [0.4031],\n",
      "        [0.3824],\n",
      "        [0.3824]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.6944],\n",
      "        [0.3056],\n",
      "        [0.4444],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n6054: \n",
      "Train loss: 0.04702599346637726      Test loss: 0.055443085730075836\n",
      "tensor([[0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189],\n",
      "        [0.4189]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.7222],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.8889],\n",
      "        [0.6944],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n6104: \n",
      "Train loss: 0.045958295464515686      Test loss: 0.03101135417819023\n",
      "tensor([[0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433],\n",
      "        [0.3433]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.8889],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n6154: \n",
      "Train loss: 0.08044610172510147      Test loss: 0.014302246272563934\n",
      "tensor([[0.4894],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4214],\n",
      "        [0.4512]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2778],\n",
      "        [0.6389],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.1944]], device='cuda:0')\n",
      "epoch n6204: \n",
      "Train loss: 0.05804711952805519      Test loss: 0.026266349479556084\n",
      "tensor([[0.4123],\n",
      "        [0.4123],\n",
      "        [0.4123],\n",
      "        [0.4248],\n",
      "        [0.4123],\n",
      "        [0.4123],\n",
      "        [0.4123],\n",
      "        [0.4123],\n",
      "        [0.4123],\n",
      "        [0.4123]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n6254: \n",
      "Train loss: 0.029853081330657005      Test loss: 0.014499613083899021\n",
      "tensor([[0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053],\n",
      "        [0.4053]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n6304: \n",
      "Train loss: 0.031196795403957367      Test loss: 0.030824486166238785\n",
      "tensor([[0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156],\n",
      "        [0.4156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n6354: \n",
      "Train loss: 0.03592666611075401      Test loss: 0.021256618201732635\n",
      "tensor([[0.3978],\n",
      "        [0.3980],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.4163],\n",
      "        [0.3978],\n",
      "        [0.3978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n6404: \n",
      "Train loss: 0.029178958386182785      Test loss: 0.015552817843854427\n",
      "tensor([[0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n6454: \n",
      "Train loss: 0.01969778537750244      Test loss: 0.03979457914829254\n",
      "tensor([[0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157],\n",
      "        [0.4157]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n6504: \n",
      "Train loss: 0.039138175547122955      Test loss: 0.016629988327622414\n",
      "tensor([[0.4046],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.4121],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.4046],\n",
      "        [0.4198]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3056],\n",
      "        [0.2500],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n6554: \n",
      "Train loss: 0.055862292647361755      Test loss: 0.021292557939887047\n",
      "tensor([[0.4059],\n",
      "        [0.4059],\n",
      "        [0.4059],\n",
      "        [0.4059],\n",
      "        [0.4059],\n",
      "        [0.4059],\n",
      "        [0.4187],\n",
      "        [0.4295],\n",
      "        [0.4378],\n",
      "        [0.4156]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n6604: \n",
      "Train loss: 0.05194362252950668      Test loss: 0.04093613103032112\n",
      "tensor([[0.3779],\n",
      "        [0.3779],\n",
      "        [0.3779],\n",
      "        [0.3779],\n",
      "        [0.3796],\n",
      "        [0.3779],\n",
      "        [0.3779],\n",
      "        [0.3779],\n",
      "        [0.3779],\n",
      "        [0.3934]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5833],\n",
      "        [0.4444],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.6389],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n6654: \n",
      "Train loss: 0.06243013218045235      Test loss: 0.022595051676034927\n",
      "tensor([[0.3934],\n",
      "        [0.3934],\n",
      "        [0.3934],\n",
      "        [0.3934],\n",
      "        [0.3934],\n",
      "        [0.3934],\n",
      "        [0.3934],\n",
      "        [0.4328],\n",
      "        [0.4263],\n",
      "        [0.3934]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n6704: \n",
      "Train loss: 0.04618816822767258      Test loss: 0.01839536987245083\n",
      "tensor([[0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3333],\n",
      "        [0.4444],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n6754: \n",
      "Train loss: 0.027890339493751526      Test loss: 0.05348142609000206\n",
      "tensor([[0.3517],\n",
      "        [0.3517],\n",
      "        [0.3517],\n",
      "        [0.3517],\n",
      "        [0.3684],\n",
      "        [0.3517],\n",
      "        [0.3517],\n",
      "        [0.3517],\n",
      "        [0.3517],\n",
      "        [0.3517]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.9167],\n",
      "        [0.5556],\n",
      "        [0.7222],\n",
      "        [0.8889],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n6804: \n",
      "Train loss: 0.054369956254959106      Test loss: 0.021338775753974915\n",
      "tensor([[0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043],\n",
      "        [0.4043]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.4722],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n6854: \n",
      "Train loss: 0.05883179232478142      Test loss: 0.022748976945877075\n",
      "tensor([[0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058],\n",
      "        [0.4058]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.8889],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n6904: \n",
      "Train loss: 0.07261805981397629      Test loss: 0.01694667711853981\n",
      "tensor([[0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879],\n",
      "        [0.3879]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n6954: \n",
      "Train loss: 0.0632835179567337      Test loss: 0.02365855872631073\n",
      "tensor([[0.4369],\n",
      "        [0.4147],\n",
      "        [0.4147],\n",
      "        [0.4347],\n",
      "        [0.4673],\n",
      "        [0.4147],\n",
      "        [0.4147],\n",
      "        [0.4823],\n",
      "        [0.4147],\n",
      "        [0.4942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.0278],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n7004: \n",
      "Train loss: 0.03272883966565132      Test loss: 0.03247905522584915\n",
      "tensor([[0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3673],\n",
      "        [0.3894],\n",
      "        [0.3673]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.7500],\n",
      "        [0.8889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n7054: \n",
      "Train loss: 0.05237853154540062      Test loss: 0.01882028765976429\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.5278],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n7104: \n",
      "Train loss: 0.04402018338441849      Test loss: 0.026654254645109177\n",
      "tensor([[0.4347],\n",
      "        [0.4357],\n",
      "        [0.4293],\n",
      "        [0.4267],\n",
      "        [0.4621],\n",
      "        [0.5043],\n",
      "        [0.4267],\n",
      "        [0.4267],\n",
      "        [0.4267],\n",
      "        [0.4482]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n7154: \n",
      "Train loss: 0.03774997964501381      Test loss: 0.03919695317745209\n",
      "tensor([[0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734],\n",
      "        [0.3734]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.4167],\n",
      "        [0.5000],\n",
      "        [0.5556],\n",
      "        [0.2500],\n",
      "        [0.7500],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n7204: \n",
      "Train loss: 0.02984916791319847      Test loss: 0.03428109735250473\n",
      "tensor([[0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n7254: \n",
      "Train loss: 0.02798866666853428      Test loss: 0.026642773300409317\n",
      "tensor([[0.3612],\n",
      "        [0.4028],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612],\n",
      "        [0.3612]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5000],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n7304: \n",
      "Train loss: 0.07659290730953217      Test loss: 0.03365079313516617\n",
      "tensor([[0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876],\n",
      "        [0.3876]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.7222],\n",
      "        [0.9167],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.3611],\n",
      "        [0.0833],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n7354: \n",
      "Train loss: 0.10313275456428528      Test loss: 0.03255540877580643\n",
      "tensor([[0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102],\n",
      "        [0.4102]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.7500],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n7404: \n",
      "Train loss: 0.04489848017692566      Test loss: 0.02344414032995701\n",
      "tensor([[0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.6389],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n7454: \n",
      "Train loss: 0.02744016796350479      Test loss: 0.021137632429599762\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.4003],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3611],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n7504: \n",
      "Train loss: 0.030695520341396332      Test loss: 0.03532724827528\n",
      "tensor([[0.3834],\n",
      "        [0.3834],\n",
      "        [0.3834],\n",
      "        [0.3834],\n",
      "        [0.3861],\n",
      "        [0.3834],\n",
      "        [0.3834],\n",
      "        [0.3834],\n",
      "        [0.3834],\n",
      "        [0.3834]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.6111],\n",
      "        [0.2500],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5000],\n",
      "        [0.9444],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n7554: \n",
      "Train loss: 0.02169092372059822      Test loss: 0.02800983190536499\n",
      "tensor([[0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932],\n",
      "        [0.3932]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.6389],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n7604: \n",
      "Train loss: 0.05290894955396652      Test loss: 0.020653802901506424\n",
      "tensor([[0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.4100],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.4130]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n7654: \n",
      "Train loss: 0.040616344660520554      Test loss: 0.012708041816949844\n",
      "tensor([[0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754],\n",
      "        [0.3754]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.2778],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n7704: \n",
      "Train loss: 0.024901917204260826      Test loss: 0.0315958671271801\n",
      "tensor([[0.4012],\n",
      "        [0.4012],\n",
      "        [0.4034],\n",
      "        [0.4012],\n",
      "        [0.4012],\n",
      "        [0.4012],\n",
      "        [0.4012],\n",
      "        [0.4012],\n",
      "        [0.4012],\n",
      "        [0.4012]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.2222],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n7754: \n",
      "Train loss: 0.050252728164196014      Test loss: 0.03583630919456482\n",
      "tensor([[0.3719],\n",
      "        [0.3719],\n",
      "        [0.3719],\n",
      "        [0.3719],\n",
      "        [0.3719],\n",
      "        [0.3719],\n",
      "        [0.3719],\n",
      "        [0.3721],\n",
      "        [0.3719],\n",
      "        [0.3719]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.9444],\n",
      "        [0.3056],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n7804: \n",
      "Train loss: 0.03218745440244675      Test loss: 0.043405596166849136\n",
      "tensor([[0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625],\n",
      "        [0.3625]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n7854: \n",
      "Train loss: 0.04249139130115509      Test loss: 0.0344751812517643\n",
      "tensor([[0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.6389],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n7904: \n",
      "Train loss: 0.06704442203044891      Test loss: 0.0227619968354702\n",
      "tensor([[0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874],\n",
      "        [0.3874]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n7954: \n",
      "Train loss: 0.062241148203611374      Test loss: 0.02692263573408127\n",
      "tensor([[0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121],\n",
      "        [0.4121]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8004: \n",
      "Train loss: 0.12719327211380005      Test loss: 0.014447864145040512\n",
      "tensor([[0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823],\n",
      "        [0.3823]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8054: \n",
      "Train loss: 0.07040674239397049      Test loss: 0.024438295513391495\n",
      "tensor([[0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8104: \n",
      "Train loss: 0.056881558150053024      Test loss: 0.0276048444211483\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.4003],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.6389],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n8154: \n",
      "Train loss: 0.038366515189409256      Test loss: 0.03387501835823059\n",
      "tensor([[0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.3886],\n",
      "        [0.4012]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.0278],\n",
      "        [0.9167],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8204: \n",
      "Train loss: 0.051351722329854965      Test loss: 0.035853125154972076\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3943]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.7500],\n",
      "        [0.4167],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8254: \n",
      "Train loss: 0.05660674721002579      Test loss: 0.027277883142232895\n",
      "tensor([[0.4042],\n",
      "        [0.4042],\n",
      "        [0.4042],\n",
      "        [0.4141],\n",
      "        [0.4042],\n",
      "        [0.4042],\n",
      "        [0.4042],\n",
      "        [0.4042],\n",
      "        [0.4042],\n",
      "        [0.4042]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.6111],\n",
      "        [0.2778],\n",
      "        [0.4722],\n",
      "        [0.8889],\n",
      "        [0.6111],\n",
      "        [0.5278],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8304: \n",
      "Train loss: 0.03838229179382324      Test loss: 0.04772710055112839\n",
      "tensor([[0.4226],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.0278],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.6389],\n",
      "        [0.7500],\n",
      "        [0.5556],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n8354: \n",
      "Train loss: 0.05389449745416641      Test loss: 0.023796366527676582\n",
      "tensor([[0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n8404: \n",
      "Train loss: 0.02835169993340969      Test loss: 0.034180447459220886\n",
      "tensor([[0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3962],\n",
      "        [0.3961],\n",
      "        [0.3961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.7222],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n8454: \n",
      "Train loss: 0.03279799595475197      Test loss: 0.025676080957055092\n",
      "tensor([[0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4062]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.5000],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n8504: \n",
      "Train loss: 0.06632058322429657      Test loss: 0.015116547234356403\n",
      "tensor([[0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991],\n",
      "        [0.3991]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n8554: \n",
      "Train loss: 0.055930234491825104      Test loss: 0.03461020439863205\n",
      "tensor([[0.3983],\n",
      "        [0.4275],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.7222],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n8604: \n",
      "Train loss: 0.036576755344867706      Test loss: 0.01863250508904457\n",
      "tensor([[0.3968],\n",
      "        [0.4096],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.0833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n8654: \n",
      "Train loss: 0.10444103926420212      Test loss: 0.029999271035194397\n",
      "tensor([[0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.4002],\n",
      "        [0.3985],\n",
      "        [0.4045],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.1944],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n8704: \n",
      "Train loss: 0.04171983152627945      Test loss: 0.02298506163060665\n",
      "tensor([[0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982],\n",
      "        [0.3982]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n8754: \n",
      "Train loss: 0.04239949211478233      Test loss: 0.029433149844408035\n",
      "tensor([[0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n8804: \n",
      "Train loss: 0.043307721614837646      Test loss: 0.016093485057353973\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.1944],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n8854: \n",
      "Train loss: 0.022651564329862595      Test loss: 0.015699336305260658\n",
      "tensor([[0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4021],\n",
      "        [0.4041],\n",
      "        [0.4021],\n",
      "        [0.4021]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.4444],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n8904: \n",
      "Train loss: 0.04481704533100128      Test loss: 0.048722509294748306\n",
      "tensor([[0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.9167],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n8954: \n",
      "Train loss: 0.09186552464962006      Test loss: 0.01622416265308857\n",
      "tensor([[0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n9004: \n",
      "Train loss: 0.06384064257144928      Test loss: 0.03190663456916809\n",
      "tensor([[0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4022],\n",
      "        [0.4046]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.3333],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n9054: \n",
      "Train loss: 0.015715772286057472      Test loss: 0.024327991530299187\n",
      "tensor([[0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3986],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3987]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n9104: \n",
      "Train loss: 0.09804906696081161      Test loss: 0.018832989037036896\n",
      "tensor([[0.4064],\n",
      "        [0.4064],\n",
      "        [0.4157],\n",
      "        [0.4064],\n",
      "        [0.4064],\n",
      "        [0.4064],\n",
      "        [0.4064],\n",
      "        [0.4064],\n",
      "        [0.4064],\n",
      "        [0.4064]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.1944],\n",
      "        [0.0278],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n9154: \n",
      "Train loss: 0.03817591071128845      Test loss: 0.03389100730419159\n",
      "tensor([[0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.5833],\n",
      "        [0.5278],\n",
      "        [0.2500],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n9204: \n",
      "Train loss: 0.02439558133482933      Test loss: 0.02875785529613495\n",
      "tensor([[0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.0833],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.8889],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n9254: \n",
      "Train loss: 0.10104440152645111      Test loss: 0.020632769912481308\n",
      "tensor([[0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916],\n",
      "        [0.3916]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.4444],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n9304: \n",
      "Train loss: 0.06970731168985367      Test loss: 0.03984568640589714\n",
      "tensor([[0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.4167],\n",
      "        [0.6389],\n",
      "        [0.8889],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.6944],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n9354: \n",
      "Train loss: 0.03037259355187416      Test loss: 0.02762347087264061\n",
      "tensor([[0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.4105],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.6389],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n9404: \n",
      "Train loss: 0.12550373375415802      Test loss: 0.03231484070420265\n",
      "tensor([[0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.6389],\n",
      "        [0.6111],\n",
      "        [0.3611],\n",
      "        [0.2778],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n9454: \n",
      "Train loss: 0.05526266247034073      Test loss: 0.023007472977042198\n",
      "tensor([[0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018],\n",
      "        [0.4018]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6389],\n",
      "        [0.5833],\n",
      "        [0.5278],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n9504: \n",
      "Train loss: 0.08384662866592407      Test loss: 0.01865885779261589\n",
      "tensor([[0.3951],\n",
      "        [0.4146],\n",
      "        [0.4017],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3984],\n",
      "        [0.3951],\n",
      "        [0.3951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n9554: \n",
      "Train loss: 0.02868743985891342      Test loss: 0.041213348507881165\n",
      "tensor([[0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900],\n",
      "        [0.3900]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.9167],\n",
      "        [0.2778],\n",
      "        [0.0833],\n",
      "        [0.6389],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n9604: \n",
      "Train loss: 0.03674566000699997      Test loss: 0.017380008473992348\n",
      "tensor([[0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888],\n",
      "        [0.3888]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.1389],\n",
      "        [0.4722],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.1944],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n9654: \n",
      "Train loss: 0.016811883077025414      Test loss: 0.02471213974058628\n",
      "tensor([[0.3929],\n",
      "        [0.3978],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n9704: \n",
      "Train loss: 0.08946254849433899      Test loss: 0.03740888833999634\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.1944],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n9754: \n",
      "Train loss: 0.04782386124134064      Test loss: 0.022492803633213043\n",
      "tensor([[0.3837],\n",
      "        [0.3837],\n",
      "        [0.3837],\n",
      "        [0.3837],\n",
      "        [0.3837],\n",
      "        [0.3837],\n",
      "        [0.3837],\n",
      "        [0.4081],\n",
      "        [0.3837],\n",
      "        [0.3837]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.6944],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n9804: \n",
      "Train loss: 0.08086977154016495      Test loss: 0.030321545898914337\n",
      "tensor([[0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3803],\n",
      "        [0.3930],\n",
      "        [0.4054],\n",
      "        [0.3803],\n",
      "        [0.3803]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n9854: \n",
      "Train loss: 0.056680142879486084      Test loss: 0.028760816901922226\n",
      "tensor([[0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908],\n",
      "        [0.3908]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.5278]], device='cuda:0')\n",
      "epoch n9904: \n",
      "Train loss: 0.05614181235432625      Test loss: 0.03657703101634979\n",
      "tensor([[0.3964],\n",
      "        [0.3964],\n",
      "        [0.4122],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.8889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n9954: \n",
      "Train loss: 0.08202590048313141      Test loss: 0.018236851319670677\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.5278],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n10004: \n",
      "Train loss: 0.03814458101987839      Test loss: 0.023363184183835983\n",
      "tensor([[0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.6944],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.6944],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n10054: \n",
      "Train loss: 0.044863611459732056      Test loss: 0.03151918575167656\n",
      "tensor([[0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.2778],\n",
      "        [0.4444],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2500]], device='cuda:0')\n",
      "epoch n10104: \n",
      "Train loss: 0.01534431055188179      Test loss: 0.01631866581737995\n",
      "tensor([[0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878],\n",
      "        [0.3878]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5278],\n",
      "        [0.4444],\n",
      "        [0.7500],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n10154: \n",
      "Train loss: 0.02770828828215599      Test loss: 0.026954784989356995\n",
      "tensor([[0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n10204: \n",
      "Train loss: 0.08513197302818298      Test loss: 0.029934875667095184\n",
      "tensor([[0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868],\n",
      "        [0.3868]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.7222],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.0833],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n10254: \n",
      "Train loss: 0.0441681444644928      Test loss: 0.029984481632709503\n",
      "tensor([[0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.4186],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.8889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n10304: \n",
      "Train loss: 0.05282878503203392      Test loss: 0.02629510685801506\n",
      "tensor([[0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.2778],\n",
      "        [0.0833],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n10354: \n",
      "Train loss: 0.030728166922926903      Test loss: 0.04502944275736809\n",
      "tensor([[0.3973],\n",
      "        [0.3973],\n",
      "        [0.3978],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.4157],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.4155]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.9167],\n",
      "        [0.7500],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n10404: \n",
      "Train loss: 0.03966766595840454      Test loss: 0.024803688749670982\n",
      "tensor([[0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.6111],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.6389],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n10454: \n",
      "Train loss: 0.06800079345703125      Test loss: 0.020665254443883896\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n10504: \n",
      "Train loss: 0.031146204099059105      Test loss: 0.01480400562286377\n",
      "tensor([[0.3852],\n",
      "        [0.3851],\n",
      "        [0.3851],\n",
      "        [0.3851],\n",
      "        [0.4022],\n",
      "        [0.3851],\n",
      "        [0.3851],\n",
      "        [0.3851],\n",
      "        [0.3851],\n",
      "        [0.3851]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.0833],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n10554: \n",
      "Train loss: 0.035836510360240936      Test loss: 0.04228632524609566\n",
      "tensor([[0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804],\n",
      "        [0.3804]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9167],\n",
      "        [0.1389],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n10604: \n",
      "Train loss: 0.030428709462285042      Test loss: 0.021570198237895966\n",
      "tensor([[0.3921],\n",
      "        [0.3929],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.4234],\n",
      "        [0.3921],\n",
      "        [0.3949]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.0833],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n10654: \n",
      "Train loss: 0.037785157561302185      Test loss: 0.04430732876062393\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.0278],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.8889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n10704: \n",
      "Train loss: 0.026134146377444267      Test loss: 0.02888849377632141\n",
      "tensor([[0.4023],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4018],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008],\n",
      "        [0.4008]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.6944],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n10754: \n",
      "Train loss: 0.01533961296081543      Test loss: 0.02720252051949501\n",
      "tensor([[0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.9167],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n10804: \n",
      "Train loss: 0.030073143541812897      Test loss: 0.026372939348220825\n",
      "tensor([[0.3836],\n",
      "        [0.3836],\n",
      "        [0.3836],\n",
      "        [0.3836],\n",
      "        [0.3836],\n",
      "        [0.4089],\n",
      "        [0.3844],\n",
      "        [0.3836],\n",
      "        [0.3836],\n",
      "        [0.3836]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.6944],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5278],\n",
      "        [0.2778],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n10854: \n",
      "Train loss: 0.06331845372915268      Test loss: 0.015500831417739391\n",
      "tensor([[0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3847],\n",
      "        [0.3850],\n",
      "        [0.3847]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n10904: \n",
      "Train loss: 0.061222098767757416      Test loss: 0.03824618458747864\n",
      "tensor([[0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n10954: \n",
      "Train loss: 0.04921574890613556      Test loss: 0.01788458228111267\n",
      "tensor([[0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.4059],\n",
      "        [0.3984],\n",
      "        [0.3984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.6389],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n11004: \n",
      "Train loss: 0.032311633229255676      Test loss: 0.018394527956843376\n",
      "tensor([[0.3960],\n",
      "        [0.3960],\n",
      "        [0.4241],\n",
      "        [0.3960],\n",
      "        [0.3960],\n",
      "        [0.3960],\n",
      "        [0.3960],\n",
      "        [0.4059],\n",
      "        [0.3960],\n",
      "        [0.3960]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n11054: \n",
      "Train loss: 0.029288185760378838      Test loss: 0.040742143988609314\n",
      "tensor([[0.3917],\n",
      "        [0.3939],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.4157],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.2500],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n11104: \n",
      "Train loss: 0.06913992762565613      Test loss: 0.015985073521733284\n",
      "tensor([[0.3933],\n",
      "        [0.4154],\n",
      "        [0.4070],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.4169]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n11154: \n",
      "Train loss: 0.022808514535427094      Test loss: 0.030991483479738235\n",
      "tensor([[0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913],\n",
      "        [0.3913]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n11204: \n",
      "Train loss: 0.038932397961616516      Test loss: 0.017817363142967224\n",
      "tensor([[0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3884],\n",
      "        [0.3886],\n",
      "        [0.3884],\n",
      "        [0.3884]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.1944]], device='cuda:0')\n",
      "epoch n11254: \n",
      "Train loss: 0.07404549419879913      Test loss: 0.03477013111114502\n",
      "tensor([[0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817],\n",
      "        [0.3817]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n11304: \n",
      "Train loss: 0.07166675478219986      Test loss: 0.03581157699227333\n",
      "tensor([[0.3842],\n",
      "        [0.3910],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842],\n",
      "        [0.3842]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n11354: \n",
      "Train loss: 0.05981839820742607      Test loss: 0.03375794738531113\n",
      "tensor([[0.3959],\n",
      "        [0.3959],\n",
      "        [0.4167],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.4274],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.2222],\n",
      "        [0.0833],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n11404: \n",
      "Train loss: 0.060371823608875275      Test loss: 0.025637393817305565\n",
      "tensor([[0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.6944],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.7500],\n",
      "        [0.5556],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n11454: \n",
      "Train loss: 0.0457664355635643      Test loss: 0.01705581694841385\n",
      "tensor([[0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.2500],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n11504: \n",
      "Train loss: 0.0468125082552433      Test loss: 0.02146548219025135\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n11554: \n",
      "Train loss: 0.06731411069631577      Test loss: 0.01455443724989891\n",
      "tensor([[0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061],\n",
      "        [0.4061]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n11604: \n",
      "Train loss: 0.05346309766173363      Test loss: 0.032414186745882034\n",
      "tensor([[0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088],\n",
      "        [0.4088]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n11654: \n",
      "Train loss: 0.05785389989614487      Test loss: 0.03170017525553703\n",
      "tensor([[0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089],\n",
      "        [0.4089]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n11704: \n",
      "Train loss: 0.06972861289978027      Test loss: 0.027859114110469818\n",
      "tensor([[0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5278],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n11754: \n",
      "Train loss: 0.050511591136455536      Test loss: 0.04655168205499649\n",
      "tensor([[0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906],\n",
      "        [0.3906]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5556],\n",
      "        [0.9167],\n",
      "        [0.3611],\n",
      "        [0.6389],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n11804: \n",
      "Train loss: 0.08538106083869934      Test loss: 0.02391025796532631\n",
      "tensor([[0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3878],\n",
      "        [0.3877]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.1389],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n11854: \n",
      "Train loss: 0.062053415924310684      Test loss: 0.021192196756601334\n",
      "tensor([[0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.4167],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.0833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n11904: \n",
      "Train loss: 0.05516106262803078      Test loss: 0.019527025520801544\n",
      "tensor([[0.4047],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n11954: \n",
      "Train loss: 0.07302980870008469      Test loss: 0.02095916122198105\n",
      "tensor([[0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.4148]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12004: \n",
      "Train loss: 0.027922404929995537      Test loss: 0.044362008571624756\n",
      "tensor([[0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.7500],\n",
      "        [0.9167],\n",
      "        [0.2778],\n",
      "        [0.7222],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n12054: \n",
      "Train loss: 0.046087853610515594      Test loss: 0.030390337109565735\n",
      "tensor([[0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.4167],\n",
      "        [0.7222],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.2500]], device='cuda:0')\n",
      "epoch n12104: \n",
      "Train loss: 0.0385253019630909      Test loss: 0.014302157796919346\n",
      "tensor([[0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n12154: \n",
      "Train loss: 0.03932987153530121      Test loss: 0.014480270445346832\n",
      "tensor([[0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.5000],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12204: \n",
      "Train loss: 0.053173016756772995      Test loss: 0.04586045444011688\n",
      "tensor([[0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.6111],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.5278],\n",
      "        [0.3333],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n12254: \n",
      "Train loss: 0.06757350265979767      Test loss: 0.017520753666758537\n",
      "tensor([[0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107],\n",
      "        [0.4107]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.0833],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.1944],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n12304: \n",
      "Train loss: 0.060551345348358154      Test loss: 0.0351044200360775\n",
      "tensor([[0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098],\n",
      "        [0.4098]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.9167],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n12354: \n",
      "Train loss: 0.04847453534603119      Test loss: 0.027285408228635788\n",
      "tensor([[0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.4127],\n",
      "        [0.3973],\n",
      "        [0.3972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.7222],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n12404: \n",
      "Train loss: 0.06531299650669098      Test loss: 0.020820358768105507\n",
      "tensor([[0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899],\n",
      "        [0.3899]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n12454: \n",
      "Train loss: 0.06588297337293625      Test loss: 0.04515586793422699\n",
      "tensor([[0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925],\n",
      "        [0.3925]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.7500],\n",
      "        [0.7222],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.0278],\n",
      "        [0.2222],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n12504: \n",
      "Train loss: 0.06087488681077957      Test loss: 0.029405798763036728\n",
      "tensor([[0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12554: \n",
      "Train loss: 0.02500119060277939      Test loss: 0.030814912170171738\n",
      "tensor([[0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041],\n",
      "        [0.4041]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.1944],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.0278],\n",
      "        [0.4167],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12604: \n",
      "Train loss: 0.08037518709897995      Test loss: 0.028895800933241844\n",
      "tensor([[0.3961],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n12654: \n",
      "Train loss: 0.060067154467105865      Test loss: 0.02737927809357643\n",
      "tensor([[0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.1389],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12704: \n",
      "Train loss: 0.04371260851621628      Test loss: 0.022254088893532753\n",
      "tensor([[0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n12754: \n",
      "Train loss: 0.0331878699362278      Test loss: 0.036771297454833984\n",
      "tensor([[0.4056],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4056],\n",
      "        [0.4057],\n",
      "        [0.4056],\n",
      "        [0.4056]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4444],\n",
      "        [0.9444],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.9444],\n",
      "        [0.4444],\n",
      "        [0.5278],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n12804: \n",
      "Train loss: 0.058047737926244736      Test loss: 0.022948987782001495\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3965],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.6389],\n",
      "        [0.4722],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n12854: \n",
      "Train loss: 0.07105115056037903      Test loss: 0.022664502263069153\n",
      "tensor([[0.3999],\n",
      "        [0.3999],\n",
      "        [0.4017],\n",
      "        [0.3999],\n",
      "        [0.3999],\n",
      "        [0.3999],\n",
      "        [0.3999],\n",
      "        [0.3999],\n",
      "        [0.3999],\n",
      "        [0.4119]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n12904: \n",
      "Train loss: 0.06848595291376114      Test loss: 0.026974493637681007\n",
      "tensor([[0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.7500],\n",
      "        [0.4722],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.4167],\n",
      "        [0.0278],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n12954: \n",
      "Train loss: 0.0924382209777832      Test loss: 0.01282502431422472\n",
      "tensor([[0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048],\n",
      "        [0.4048]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n13004: \n",
      "Train loss: 0.045557066798210144      Test loss: 0.020251426845788956\n",
      "tensor([[0.3998],\n",
      "        [0.3998],\n",
      "        [0.4058],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n13054: \n",
      "Train loss: 0.03500919044017792      Test loss: 0.02688228152692318\n",
      "tensor([[0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3960],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n13104: \n",
      "Train loss: 0.028167162090539932      Test loss: 0.024201124906539917\n",
      "tensor([[0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5278],\n",
      "        [0.5278],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.6944],\n",
      "        [0.2222],\n",
      "        [0.1944]], device='cuda:0')\n",
      "epoch n13154: \n",
      "Train loss: 0.03499860316514969      Test loss: 0.033296070992946625\n",
      "tensor([[0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911],\n",
      "        [0.3911]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.6389],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n13204: \n",
      "Train loss: 0.06704066693782806      Test loss: 0.040276654064655304\n",
      "tensor([[0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.6389],\n",
      "        [0.8889],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.9444]], device='cuda:0')\n",
      "epoch n13254: \n",
      "Train loss: 0.05081094801425934      Test loss: 0.03882749006152153\n",
      "tensor([[0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3921],\n",
      "        [0.3914],\n",
      "        [0.3994],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914],\n",
      "        [0.3914]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.5278],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.8889],\n",
      "        [0.2222],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n13304: \n",
      "Train loss: 0.036200396716594696      Test loss: 0.027143659070134163\n",
      "tensor([[0.3863],\n",
      "        [0.3863],\n",
      "        [0.3867],\n",
      "        [0.3865],\n",
      "        [0.3863],\n",
      "        [0.3863],\n",
      "        [0.3863],\n",
      "        [0.3863],\n",
      "        [0.3923],\n",
      "        [0.3863]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n13354: \n",
      "Train loss: 0.02844715118408203      Test loss: 0.021756455302238464\n",
      "tensor([[0.3864],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862],\n",
      "        [0.3862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n13404: \n",
      "Train loss: 0.053596965968608856      Test loss: 0.02491270750761032\n",
      "tensor([[0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877],\n",
      "        [0.3877]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n13454: \n",
      "Train loss: 0.011408628895878792      Test loss: 0.030513832345604897\n",
      "tensor([[0.4013],\n",
      "        [0.4013],\n",
      "        [0.4013],\n",
      "        [0.4013],\n",
      "        [0.4013],\n",
      "        [0.4013],\n",
      "        [0.4170],\n",
      "        [0.4013],\n",
      "        [0.4013],\n",
      "        [0.4065]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n13504: \n",
      "Train loss: 0.04629262536764145      Test loss: 0.0242621973156929\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.4105]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n13554: \n",
      "Train loss: 0.05068163201212883      Test loss: 0.021400028839707375\n",
      "tensor([[0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904],\n",
      "        [0.3904]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3611],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.7222]], device='cuda:0')\n",
      "epoch n13604: \n",
      "Train loss: 0.11811687052249908      Test loss: 0.037542060017585754\n",
      "tensor([[0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3925],\n",
      "        [0.3915],\n",
      "        [0.3919],\n",
      "        [0.3915],\n",
      "        [0.3929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.6389],\n",
      "        [0.3611],\n",
      "        [0.4167],\n",
      "        [0.0278],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n13654: \n",
      "Train loss: 0.025521770119667053      Test loss: 0.030445940792560577\n",
      "tensor([[0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915],\n",
      "        [0.3915]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n13704: \n",
      "Train loss: 0.024438798427581787      Test loss: 0.032516829669475555\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.9167],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n13754: \n",
      "Train loss: 0.04428385943174362      Test loss: 0.025766883045434952\n",
      "tensor([[0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.5000],\n",
      "        [0.3611],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n13804: \n",
      "Train loss: 0.027967598289251328      Test loss: 0.023954804986715317\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.7500],\n",
      "        [0.3056],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n13854: \n",
      "Train loss: 0.03860931843519211      Test loss: 0.024955227971076965\n",
      "tensor([[0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4085],\n",
      "        [0.4255],\n",
      "        [0.4085]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n13904: \n",
      "Train loss: 0.03529686480760574      Test loss: 0.025246163830161095\n",
      "tensor([[0.4070],\n",
      "        [0.4070],\n",
      "        [0.4070],\n",
      "        [0.4070],\n",
      "        [0.4070],\n",
      "        [0.4070],\n",
      "        [0.4070],\n",
      "        [0.4075],\n",
      "        [0.4070],\n",
      "        [0.4070]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.7222],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n13954: \n",
      "Train loss: 0.052033256739377975      Test loss: 0.045621924102306366\n",
      "tensor([[0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.9167],\n",
      "        [0.4444],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n14004: \n",
      "Train loss: 0.03782280907034874      Test loss: 0.01570521481335163\n",
      "tensor([[0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019],\n",
      "        [0.4019]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n14054: \n",
      "Train loss: 0.043426744639873505      Test loss: 0.025653047487139702\n",
      "tensor([[0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4362],\n",
      "        [0.4010]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.5278],\n",
      "        [0.2500],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n14104: \n",
      "Train loss: 0.04402332007884979      Test loss: 0.020605217665433884\n",
      "tensor([[0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010],\n",
      "        [0.4010]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.8889],\n",
      "        [0.4722],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n14154: \n",
      "Train loss: 0.1330627202987671      Test loss: 0.021727295592427254\n",
      "tensor([[0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.2500],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n14204: \n",
      "Train loss: 0.05048934370279312      Test loss: 0.028223175555467606\n",
      "tensor([[0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992],\n",
      "        [0.3992]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.0833],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.4722],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n14254: \n",
      "Train loss: 0.06928131729364395      Test loss: 0.03272742033004761\n",
      "tensor([[0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0278],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.8889],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n14304: \n",
      "Train loss: 0.03634344041347504      Test loss: 0.017488915473222733\n",
      "tensor([[0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.4935],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n14354: \n",
      "Train loss: 0.023618392646312714      Test loss: 0.018252737820148468\n",
      "tensor([[0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.1389],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n14404: \n",
      "Train loss: 0.05235869064927101      Test loss: 0.029357410967350006\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4167],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.9167],\n",
      "        [0.5833],\n",
      "        [0.0833],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n14454: \n",
      "Train loss: 0.06966736912727356      Test loss: 0.02945118397474289\n",
      "tensor([[0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n14504: \n",
      "Train loss: 0.05840020626783371      Test loss: 0.022894863039255142\n",
      "tensor([[0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958],\n",
      "        [0.3958]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n14554: \n",
      "Train loss: 0.060695089399814606      Test loss: 0.03284210339188576\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5833],\n",
      "        [0.6389],\n",
      "        [0.5000],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.7222],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n14604: \n",
      "Train loss: 0.08869846910238266      Test loss: 0.013564816676080227\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n14654: \n",
      "Train loss: 0.01743663102388382      Test loss: 0.023195430636405945\n",
      "tensor([[0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5278]], device='cuda:0')\n",
      "epoch n14704: \n",
      "Train loss: 0.056674640625715256      Test loss: 0.049407172948122025\n",
      "tensor([[0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n14754: \n",
      "Train loss: 0.08226166665554047      Test loss: 0.025057418271899223\n",
      "tensor([[0.3967],\n",
      "        [0.4230],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967],\n",
      "        [0.3967]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n14804: \n",
      "Train loss: 0.025230400264263153      Test loss: 0.01946360245347023\n",
      "tensor([[0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.4537],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.4167],\n",
      "        [0.2778],\n",
      "        [0.4722],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.4444]], device='cuda:0')\n",
      "epoch n14854: \n",
      "Train loss: 0.0373619981110096      Test loss: 0.02462715655565262\n",
      "tensor([[0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965],\n",
      "        [0.3965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n14904: \n",
      "Train loss: 0.045238345861434937      Test loss: 0.03571515530347824\n",
      "tensor([[0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.9167],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.5278]], device='cuda:0')\n",
      "epoch n14954: \n",
      "Train loss: 0.0461808517575264      Test loss: 0.037377145141363144\n",
      "tensor([[0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977],\n",
      "        [0.3977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n15004: \n",
      "Train loss: 0.03836117684841156      Test loss: 0.03518317639827728\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.5278],\n",
      "        [0.7222],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n15054: \n",
      "Train loss: 0.056629378348588943      Test loss: 0.018676187843084335\n",
      "tensor([[0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.4118],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n15104: \n",
      "Train loss: 0.07417911291122437      Test loss: 0.019938187673687935\n",
      "tensor([[0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978],\n",
      "        [0.3978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.4444],\n",
      "        [0.3056],\n",
      "        [0.5278]], device='cuda:0')\n",
      "epoch n15154: \n",
      "Train loss: 0.06155286729335785      Test loss: 0.024922482669353485\n",
      "tensor([[0.4226],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.4091],\n",
      "        [0.3974],\n",
      "        [0.3974],\n",
      "        [0.3974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.8889],\n",
      "        [0.3056],\n",
      "        [0.7500],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n15204: \n",
      "Train loss: 0.0452972911298275      Test loss: 0.02076083794236183\n",
      "tensor([[0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975],\n",
      "        [0.3975]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.6389],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n15254: \n",
      "Train loss: 0.0657292827963829      Test loss: 0.02858908660709858\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.6389],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.9444],\n",
      "        [0.6111],\n",
      "        [0.4444],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n15304: \n",
      "Train loss: 0.0457792654633522      Test loss: 0.02416297420859337\n",
      "tensor([[0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968],\n",
      "        [0.3968]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n15354: \n",
      "Train loss: 0.0445929691195488      Test loss: 0.0181441493332386\n",
      "tensor([[0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5000],\n",
      "        [0.0833],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n15404: \n",
      "Train loss: 0.058177173137664795      Test loss: 0.030398819595575333\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3333],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n15454: \n",
      "Train loss: 0.04385935142636299      Test loss: 0.03997348994016647\n",
      "tensor([[0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976],\n",
      "        [0.3976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.3889],\n",
      "        [0.6944],\n",
      "        [0.5833],\n",
      "        [0.9167],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n15504: \n",
      "Train loss: 0.05130740627646446      Test loss: 0.031623855233192444\n",
      "tensor([[0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984],\n",
      "        [0.3984]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.9167],\n",
      "        [0.6389],\n",
      "        [0.6111],\n",
      "        [0.6389],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n15554: \n",
      "Train loss: 0.06321827322244644      Test loss: 0.02310452237725258\n",
      "tensor([[0.4206],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983],\n",
      "        [0.3983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3056],\n",
      "        [0.1389],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.0278],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n15604: \n",
      "Train loss: 0.07563699036836624      Test loss: 0.024986175820231438\n",
      "tensor([[0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985],\n",
      "        [0.3985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5000],\n",
      "        [0.1944],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n15654: \n",
      "Train loss: 0.02735164761543274      Test loss: 0.025445925071835518\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.4470],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.4444],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.7222],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.0833],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n15704: \n",
      "Train loss: 0.043316617608070374      Test loss: 0.03010876104235649\n",
      "tensor([[0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989],\n",
      "        [0.3989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2500],\n",
      "        [0.9444],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.7500],\n",
      "        [0.6389],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n15754: \n",
      "Train loss: 0.05541674792766571      Test loss: 0.021625015884637833\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.4172],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.0833],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n15804: \n",
      "Train loss: 0.03701350837945938      Test loss: 0.013714748434722424\n",
      "tensor([[0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998],\n",
      "        [0.3998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.7222],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.5278],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n15854: \n",
      "Train loss: 0.0741538405418396      Test loss: 0.03739847615361214\n",
      "tensor([[0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4134],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001],\n",
      "        [0.4001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.9167],\n",
      "        [0.2222],\n",
      "        [0.4444],\n",
      "        [0.4722],\n",
      "        [0.2500],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n15904: \n",
      "Train loss: 0.02304621785879135      Test loss: 0.029073791578412056\n",
      "tensor([[0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995],\n",
      "        [0.3995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3056],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n15954: \n",
      "Train loss: 0.08591856062412262      Test loss: 0.030043363571166992\n",
      "tensor([[0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990],\n",
      "        [0.3990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.4722],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n16004: \n",
      "Train loss: 0.08779288828372955      Test loss: 0.02162671461701393\n",
      "tensor([[0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980],\n",
      "        [0.3980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n16054: \n",
      "Train loss: 0.08412845432758331      Test loss: 0.017104193568229675\n",
      "tensor([[0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979],\n",
      "        [0.3979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.1389],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4444]], device='cuda:0')\n",
      "epoch n16104: \n",
      "Train loss: 0.05446871370077133      Test loss: 0.02647138386964798\n",
      "tensor([[0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.0833],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n16154: \n",
      "Train loss: 0.05347457528114319      Test loss: 0.04149583727121353\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3981],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.0833],\n",
      "        [0.2778],\n",
      "        [0.7500],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16204: \n",
      "Train loss: 0.08059055358171463      Test loss: 0.02731591835618019\n",
      "tensor([[0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.4882],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970],\n",
      "        [0.3970]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.9167],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n16254: \n",
      "Train loss: 0.024279113858938217      Test loss: 0.035255178809165955\n",
      "tensor([[0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966],\n",
      "        [0.3966]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.4722],\n",
      "        [0.3333],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n16304: \n",
      "Train loss: 0.04004371911287308      Test loss: 0.03484482690691948\n",
      "tensor([[0.4794],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959],\n",
      "        [0.3959]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4444],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n16354: \n",
      "Train loss: 0.03630829602479935      Test loss: 0.029718715697526932\n",
      "tensor([[0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.8889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.7500],\n",
      "        [0.4444],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16404: \n",
      "Train loss: 0.053683359175920486      Test loss: 0.03445546701550484\n",
      "tensor([[0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963],\n",
      "        [0.3963]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.4722],\n",
      "        [0.9167],\n",
      "        [0.7500],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16454: \n",
      "Train loss: 0.04319653660058975      Test loss: 0.023049259558320045\n",
      "tensor([[0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.0833],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.7500],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n16504: \n",
      "Train loss: 0.09155919402837753      Test loss: 0.03779757022857666\n",
      "tensor([[0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957],\n",
      "        [0.3957]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7500],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.0278],\n",
      "        [0.6111],\n",
      "        [0.5000],\n",
      "        [0.2778],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n16554: \n",
      "Train loss: 0.04539733752608299      Test loss: 0.024164311587810516\n",
      "tensor([[0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3982],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961],\n",
      "        [0.3961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.6389],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16604: \n",
      "Train loss: 0.09494276344776154      Test loss: 0.02441329136490822\n",
      "tensor([[0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.8889],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.6389],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16654: \n",
      "Train loss: 0.0489494726061821      Test loss: 0.0230136439204216\n",
      "tensor([[0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4444],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n16704: \n",
      "Train loss: 0.027905825525522232      Test loss: 0.021834801882505417\n",
      "tensor([[0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n16754: \n",
      "Train loss: 0.06330595910549164      Test loss: 0.0185428224503994\n",
      "tensor([[0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.7222],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.2500]], device='cuda:0')\n",
      "epoch n16804: \n",
      "Train loss: 0.13912631571292877      Test loss: 0.02350323088467121\n",
      "tensor([[0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.6111],\n",
      "        [0.4444],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n16854: \n",
      "Train loss: 0.036415889859199524      Test loss: 0.01987537369132042\n",
      "tensor([[0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.2500],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n16904: \n",
      "Train loss: 0.04477955028414726      Test loss: 0.04060628265142441\n",
      "tensor([[0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6389],\n",
      "        [0.7500],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n16954: \n",
      "Train loss: 0.07863335311412811      Test loss: 0.04025408625602722\n",
      "tensor([[0.3940],\n",
      "        [0.3940],\n",
      "        [0.3940],\n",
      "        [0.3940],\n",
      "        [0.4144],\n",
      "        [0.3940],\n",
      "        [0.3940],\n",
      "        [0.4160],\n",
      "        [0.3940],\n",
      "        [0.3940]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n17004: \n",
      "Train loss: 0.07024391740560532      Test loss: 0.02918250486254692\n",
      "tensor([[0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3981],\n",
      "        [0.3935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.2500],\n",
      "        [0.6111],\n",
      "        [0.4444],\n",
      "        [0.5000],\n",
      "        [0.4722],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n17054: \n",
      "Train loss: 0.03426755592226982      Test loss: 0.023577619343996048\n",
      "tensor([[0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.6389],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n17104: \n",
      "Train loss: 0.06581123173236847      Test loss: 0.02519947662949562\n",
      "tensor([[0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.2778],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.7222],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n17154: \n",
      "Train loss: 0.07448247075080872      Test loss: 0.03595000505447388\n",
      "tensor([[0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.4144],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3056],\n",
      "        [0.3611],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.8889],\n",
      "        [0.8889],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n17204: \n",
      "Train loss: 0.05036212503910065      Test loss: 0.05016835033893585\n",
      "tensor([[0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.9444],\n",
      "        [0.5556],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.7222],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n17254: \n",
      "Train loss: 0.07915543019771576      Test loss: 0.02602875977754593\n",
      "tensor([[0.4192],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946],\n",
      "        [0.3946]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.2778],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.7500],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n17304: \n",
      "Train loss: 0.025831788778305054      Test loss: 0.029802918434143066\n",
      "tensor([[0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.6944],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.6944]], device='cuda:0')\n",
      "epoch n17354: \n",
      "Train loss: 0.10356873273849487      Test loss: 0.014407851733267307\n",
      "tensor([[0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3611],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5278],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n17404: \n",
      "Train loss: 0.06882232427597046      Test loss: 0.04047180712223053\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0833],\n",
      "        [0.3333],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.4167],\n",
      "        [0.8889]], device='cuda:0')\n",
      "epoch n17454: \n",
      "Train loss: 0.04316682368516922      Test loss: 0.021732516586780548\n",
      "tensor([[0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.4033],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7222],\n",
      "        [0.1944],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n17504: \n",
      "Train loss: 0.04372866451740265      Test loss: 0.017907066270709038\n",
      "tensor([[0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.3945],\n",
      "        [0.4038],\n",
      "        [0.3945]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.6389],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n17554: \n",
      "Train loss: 0.054359860718250275      Test loss: 0.02580319531261921\n",
      "tensor([[0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.5556],\n",
      "        [0.5278],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n17604: \n",
      "Train loss: 0.06303273141384125      Test loss: 0.04009797424077988\n",
      "tensor([[0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935],\n",
      "        [0.3935]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.8889],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.7222],\n",
      "        [0.6111],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n17654: \n",
      "Train loss: 0.05201665312051773      Test loss: 0.026566622778773308\n",
      "tensor([[0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2222],\n",
      "        [0.3333],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n17704: \n",
      "Train loss: 0.03694792836904526      Test loss: 0.02245304547250271\n",
      "tensor([[0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3959],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n17754: \n",
      "Train loss: 0.050413548946380615      Test loss: 0.03472437709569931\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.7500],\n",
      "        [0.5000],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.5833],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n17804: \n",
      "Train loss: 0.09522745758295059      Test loss: 0.03049916960299015\n",
      "tensor([[0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.8889],\n",
      "        [0.4167],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.5000],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n17854: \n",
      "Train loss: 0.06321705877780914      Test loss: 0.0244838148355484\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.4140]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4167],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.6111],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.4444],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n17904: \n",
      "Train loss: 0.05492168664932251      Test loss: 0.04223395884037018\n",
      "tensor([[0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.3933],\n",
      "        [0.4257]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.6944],\n",
      "        [0.3889],\n",
      "        [0.2500],\n",
      "        [0.5556],\n",
      "        [0.6944],\n",
      "        [0.2222],\n",
      "        [0.0833]], device='cuda:0')\n",
      "epoch n17954: \n",
      "Train loss: 0.06958315521478653      Test loss: 0.02297031693160534\n",
      "tensor([[0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938],\n",
      "        [0.3938]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n18004: \n",
      "Train loss: 0.022075526416301727      Test loss: 0.01947566494345665\n",
      "tensor([[0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3943],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.4167],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n18054: \n",
      "Train loss: 0.06247954070568085      Test loss: 0.022506294772028923\n",
      "tensor([[0.3928],\n",
      "        [0.3958],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.4444],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n18104: \n",
      "Train loss: 0.03744729608297348      Test loss: 0.01824420690536499\n",
      "tensor([[0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.3930],\n",
      "        [0.4121],\n",
      "        [0.3930],\n",
      "        [0.3930]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.2778],\n",
      "        [0.6111],\n",
      "        [0.3611],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n18154: \n",
      "Train loss: 0.036150962114334106      Test loss: 0.030607642605900764\n",
      "tensor([[0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929],\n",
      "        [0.3929]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.2778],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.4444],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n18204: \n",
      "Train loss: 0.0180934090167284      Test loss: 0.016545936465263367\n",
      "tensor([[0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926],\n",
      "        [0.3926]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.2500],\n",
      "        [0.2778],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n18254: \n",
      "Train loss: 0.06805524975061417      Test loss: 0.01187969371676445\n",
      "tensor([[0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.3928],\n",
      "        [0.4828],\n",
      "        [0.3928],\n",
      "        [0.3928]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3611],\n",
      "        [0.4167],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n18304: \n",
      "Train loss: 0.0630895271897316      Test loss: 0.01612764783203602\n",
      "tensor([[0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921],\n",
      "        [0.3921]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.3333],\n",
      "        [0.5833],\n",
      "        [0.6389],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.3611],\n",
      "        [0.3056],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n18354: \n",
      "Train loss: 0.03870280832052231      Test loss: 0.017165780067443848\n",
      "tensor([[0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917],\n",
      "        [0.3917]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.3611],\n",
      "        [0.4444],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n18404: \n",
      "Train loss: 0.030675143003463745      Test loss: 0.028125908225774765\n",
      "tensor([[0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919],\n",
      "        [0.3919]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.7500],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n18454: \n",
      "Train loss: 0.07656459510326385      Test loss: 0.012968006543815136\n",
      "tensor([[0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918],\n",
      "        [0.3918]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n18504: \n",
      "Train loss: 0.05948789417743683      Test loss: 0.021099762991070747\n",
      "tensor([[0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.4244],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931],\n",
      "        [0.3931]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.0278],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n18554: \n",
      "Train loss: 0.036482520401477814      Test loss: 0.035491444170475006\n",
      "tensor([[0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922],\n",
      "        [0.3922]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.6111],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.9167],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n18604: \n",
      "Train loss: 0.03758726641535759      Test loss: 0.03340962529182434\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.5000],\n",
      "        [0.4444],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.4167],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n18654: \n",
      "Train loss: 0.0208456888794899      Test loss: 0.014686351642012596\n",
      "tensor([[0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.4722],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n18704: \n",
      "Train loss: 0.0445525124669075      Test loss: 0.02231571078300476\n",
      "tensor([[0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937],\n",
      "        [0.3937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.4444],\n",
      "        [0.5000],\n",
      "        [0.0833],\n",
      "        [0.3889],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n18754: \n",
      "Train loss: 0.028765356168150902      Test loss: 0.020952455699443817\n",
      "tensor([[0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936],\n",
      "        [0.3936]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5000],\n",
      "        [0.3056],\n",
      "        [0.3889],\n",
      "        [0.4444],\n",
      "        [0.2222],\n",
      "        [0.6389]], device='cuda:0')\n",
      "epoch n18804: \n",
      "Train loss: 0.029426177963614464      Test loss: 0.024544546380639076\n",
      "tensor([[0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950],\n",
      "        [0.3950]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.6111],\n",
      "        [0.5000],\n",
      "        [0.2500],\n",
      "        [0.3889],\n",
      "        [0.4722],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5556]], device='cuda:0')\n",
      "epoch n18854: \n",
      "Train loss: 0.028015553951263428      Test loss: 0.022745072841644287\n",
      "tensor([[0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944],\n",
      "        [0.3944]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.6944],\n",
      "        [0.4167],\n",
      "        [0.5000],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.7500]], device='cuda:0')\n",
      "epoch n18904: \n",
      "Train loss: 0.0835532397031784      Test loss: 0.032228969037532806\n",
      "tensor([[0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941],\n",
      "        [0.3941]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.6389],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.9444]], device='cuda:0')\n",
      "epoch n18954: \n",
      "Train loss: 0.05072881281375885      Test loss: 0.03293393552303314\n",
      "tensor([[0.3959],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.4286]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5556],\n",
      "        [0.2222],\n",
      "        [0.0278],\n",
      "        [0.7222],\n",
      "        [0.2222],\n",
      "        [0.1389],\n",
      "        [0.3333],\n",
      "        [0.4722],\n",
      "        [0.4167],\n",
      "        [0.6111]], device='cuda:0')\n",
      "epoch n19004: \n",
      "Train loss: 0.0186325516551733      Test loss: 0.025320878252387047\n",
      "tensor([[0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.4166],\n",
      "        [0.3948]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.7500],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.7222],\n",
      "        [0.4167],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n19054: \n",
      "Train loss: 0.04268070310354233      Test loss: 0.016108376905322075\n",
      "tensor([[0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3983],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.3947],\n",
      "        [0.4188],\n",
      "        [0.3947]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.2778],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.5556],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.0278],\n",
      "        [0.5833],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n19104: \n",
      "Train loss: 0.035098567605018616      Test loss: 0.03397105261683464\n",
      "tensor([[0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3952],\n",
      "        [0.3953],\n",
      "        [0.3952]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.6111],\n",
      "        [0.5556],\n",
      "        [0.3056],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.2778],\n",
      "        [0.3889],\n",
      "        [0.7500],\n",
      "        [0.2778]], device='cuda:0')\n",
      "epoch n19154: \n",
      "Train loss: 0.08986607939004898      Test loss: 0.029146816581487656\n",
      "tensor([[0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964],\n",
      "        [0.3964]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5278],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.5278],\n",
      "        [0.4722],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.1389],\n",
      "        [0.3333],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n19204: \n",
      "Train loss: 0.04293430224061012      Test loss: 0.01240165252238512\n",
      "tensor([[0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.4082],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3611],\n",
      "        [0.5556],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.4167],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n19254: \n",
      "Train loss: 0.04468488693237305      Test loss: 0.023297179490327835\n",
      "tensor([[0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969],\n",
      "        [0.3969]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.4722],\n",
      "        [0.7500],\n",
      "        [0.4167],\n",
      "        [0.1944],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.4722],\n",
      "        [0.3056]], device='cuda:0')\n",
      "epoch n19304: \n",
      "Train loss: 0.06950896978378296      Test loss: 0.01314542070031166\n",
      "tensor([[0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971],\n",
      "        [0.3971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.3611],\n",
      "        [0.2222],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n19354: \n",
      "Train loss: 0.03170255199074745      Test loss: 0.026508787646889687\n",
      "tensor([[0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972],\n",
      "        [0.3972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.7500],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.2222],\n",
      "        [0.3333]], device='cuda:0')\n",
      "epoch n19404: \n",
      "Train loss: 0.029163746163249016      Test loss: 0.035420771688222885\n",
      "tensor([[0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.3973],\n",
      "        [0.4102],\n",
      "        [0.3973]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.1944],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.5556],\n",
      "        [0.2222],\n",
      "        [0.9167],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3611]], device='cuda:0')\n",
      "epoch n19454: \n",
      "Train loss: 0.04083754122257233      Test loss: 0.034677904099226\n",
      "tensor([[0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962],\n",
      "        [0.3962]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3889],\n",
      "        [0.3056],\n",
      "        [0.2222],\n",
      "        [0.4167],\n",
      "        [0.2222],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.5833],\n",
      "        [0.4722],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n19504: \n",
      "Train loss: 0.06305214762687683      Test loss: 0.033147409558296204\n",
      "tensor([[0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.2222],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.7222],\n",
      "        [0.8889],\n",
      "        [0.4444],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n19554: \n",
      "Train loss: 0.07906897366046906      Test loss: 0.02026553638279438\n",
      "tensor([[0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956],\n",
      "        [0.3956]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.6111],\n",
      "        [0.3889],\n",
      "        [0.2222],\n",
      "        [0.2778],\n",
      "        [0.3611],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.2500]], device='cuda:0')\n",
      "epoch n19604: \n",
      "Train loss: 0.0541003979742527      Test loss: 0.02673538401722908\n",
      "tensor([[0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948],\n",
      "        [0.3948]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.0833],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.6111],\n",
      "        [0.8889],\n",
      "        [0.5000]], device='cuda:0')\n",
      "epoch n19654: \n",
      "Train loss: 0.07066094875335693      Test loss: 0.021665411069989204\n",
      "tensor([[0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951],\n",
      "        [0.3951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3333],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.3056],\n",
      "        [0.6389],\n",
      "        [0.4722],\n",
      "        [0.2222],\n",
      "        [0.5833]], device='cuda:0')\n",
      "epoch n19704: \n",
      "Train loss: 0.03635719418525696      Test loss: 0.012844274751842022\n",
      "tensor([[0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954],\n",
      "        [0.3954]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5000],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3889],\n",
      "        [0.3056],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889]], device='cuda:0')\n",
      "epoch n19754: \n",
      "Train loss: 0.045238107442855835      Test loss: 0.020977742969989777\n",
      "tensor([[0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949],\n",
      "        [0.3949]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.3056],\n",
      "        [0.6111],\n",
      "        [0.4167],\n",
      "        [0.3056],\n",
      "        [0.5833],\n",
      "        [0.5833],\n",
      "        [0.4444],\n",
      "        [0.3333],\n",
      "        [0.2222],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n19804: \n",
      "Train loss: 0.05629723519086838      Test loss: 0.033005520701408386\n",
      "tensor([[0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.3889],\n",
      "        [0.3889],\n",
      "        [0.0833],\n",
      "        [0.2778],\n",
      "        [0.3056],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.4722]], device='cuda:0')\n",
      "epoch n19854: \n",
      "Train loss: 0.017537234351038933      Test loss: 0.03106580302119255\n",
      "tensor([[0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942],\n",
      "        [0.3942]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.2778],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.3333],\n",
      "        [0.3889],\n",
      "        [0.6111],\n",
      "        [0.5833],\n",
      "        [0.5556],\n",
      "        [0.6389],\n",
      "        [0.4167]], device='cuda:0')\n",
      "epoch n19904: \n",
      "Train loss: 0.050680506974458694      Test loss: 0.03745903819799423\n",
      "tensor([[0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.3943],\n",
      "        [0.4148],\n",
      "        [0.3943]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5556],\n",
      "        [0.3889],\n",
      "        [0.3333],\n",
      "        [0.3333],\n",
      "        [0.7222],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.0278],\n",
      "        [0.2222]], device='cuda:0')\n",
      "epoch n19954: \n",
      "Train loss: 0.06448512524366379      Test loss: 0.03622756525874138\n",
      "tensor([[0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939],\n",
      "        [0.3939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.6944],\n",
      "        [0.2222],\n",
      "        [0.3611],\n",
      "        [0.3889],\n",
      "        [0.9444],\n",
      "        [0.2222],\n",
      "        [0.3889],\n",
      "        [0.5556],\n",
      "        [0.2778]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "epochs = 20000\n",
    "lr_base = 0.01\n",
    "lr_decay_epochs = [8000,14000]\n",
    "lr_decay_factor = 0.1\n",
    "net = ResNet18_embed().to(device).float()\n",
    "net = nn.DataParallel(net)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr_base)\n",
    "\n",
    "#train loop\n",
    "\n",
    "for ep in range(epochs):\n",
    "    net.train()\n",
    "    adjust_learning_rate_1(optimizer, ep)\n",
    "    optimizer.zero_grad()\n",
    "    imgs, labels = next(iter(train_loader))\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    out , _ = net(imgs)\n",
    "    lossT = criterion(out, labels)\n",
    "    lossT.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if ep%50 == 4:\n",
    "        net.eval()\n",
    "        imgs, labels = next(iter(test_loader))\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out, _ = net(imgs)\n",
    "        lossV = criterion(out, labels)\n",
    "        print(f\"epoch n{ep}: \\nTrain loss: {lossT}      Test loss: {lossV}\")\n",
    "        print(out[:10])\n",
    "        print(labels[:10])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving network\n",
    "\n",
    "PATH = \"models/embed/embed128_RPM.pth\"\n",
    "torch.save({\n",
    "                    'epoch': ep,\n",
    "                    'net_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'rng_state': torch.get_rng_state()\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loading of h2y part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "PATH = \"models/embed/embed128_RPM.pth\"\n",
    "\n",
    "test = ResNet18_embed()\n",
    "test = nn.DataParallel(test)\n",
    "\n",
    "cp = torch.load(PATH)\n",
    "test.load_state_dict(cp['net_state_dict'])\n",
    "\n",
    "print(test.module.h2y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Inversion of h2y layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labels_Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        #return len(self.list_IDs)\n",
    "        return ids.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        y = LabelsTens[index]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_y2h(nn.Module):\n",
    "    def __init__(self, dim_embed=DIM_EMBED):\n",
    "        super(model_y2h, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(1, dim_embed),\n",
    "            # nn.BatchNorm1d(dim_embed),\n",
    "            nn.GroupNorm(8, dim_embed),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(dim_embed, dim_embed),\n",
    "            # nn.BatchNorm1d(dim_embed),\n",
    "            nn.GroupNorm(8, dim_embed),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(dim_embed, dim_embed),\n",
    "            # nn.BatchNorm1d(dim_embed),\n",
    "            nn.GroupNorm(8, dim_embed),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(dim_embed, dim_embed),\n",
    "            # nn.BatchNorm1d(dim_embed),\n",
    "            nn.GroupNorm(8, dim_embed),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(dim_embed, dim_embed),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, y):\n",
    "        y = y.view(-1, 1) +1e-8\n",
    "        # y = torch.exp(y.view(-1, 1))\n",
    "        return self.main(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing forward of y2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "y2h = model_y2h()\n",
    "\n",
    "test = torch.rand(1)\n",
    "out = y2h.forward(test)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the y2h model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch n0: \n",
      "Train loss: 0.09496907889842987\n",
      "epoch n15: \n",
      "Train loss: 0.005522364750504494\n",
      "epoch n30: \n",
      "Train loss: 0.0016289176419377327\n",
      "epoch n45: \n",
      "Train loss: 0.0006877310806885362\n",
      "epoch n60: \n",
      "Train loss: 0.0001888959523057565\n",
      "epoch n75: \n",
      "Train loss: 8.460896788164973e-05\n",
      "epoch n90: \n",
      "Train loss: 9.676367335487157e-05\n",
      "epoch n105: \n",
      "Train loss: 7.796823047101498e-05\n",
      "epoch n120: \n",
      "Train loss: 5.7650624512461945e-05\n",
      "epoch n135: \n",
      "Train loss: 6.11416035098955e-05\n",
      "epoch n150: \n",
      "Train loss: 4.6313623897731304e-05\n",
      "epoch n165: \n",
      "Train loss: 3.7244804843794554e-05\n",
      "epoch n180: \n",
      "Train loss: 4.047958645969629e-05\n",
      "epoch n195: \n",
      "Train loss: 5.788499765913002e-05\n",
      "epoch n210: \n",
      "Train loss: 5.214629345573485e-05\n",
      "epoch n225: \n",
      "Train loss: 3.6499266570899636e-05\n",
      "epoch n240: \n",
      "Train loss: 2.5406188797205687e-05\n",
      "epoch n255: \n",
      "Train loss: 3.1988995033316314e-05\n",
      "epoch n270: \n",
      "Train loss: 4.3366362660890445e-05\n",
      "epoch n285: \n",
      "Train loss: 3.173809091094881e-05\n",
      "epoch n300: \n",
      "Train loss: 3.482646570773795e-05\n",
      "epoch n315: \n",
      "Train loss: 4.4627282477449626e-05\n",
      "epoch n330: \n",
      "Train loss: 3.0661802156828344e-05\n",
      "epoch n345: \n",
      "Train loss: 5.9126439737156034e-05\n",
      "epoch n360: \n",
      "Train loss: 4.034141602460295e-05\n",
      "epoch n375: \n",
      "Train loss: 4.054507735418156e-05\n",
      "epoch n390: \n",
      "Train loss: 3.290307358838618e-05\n",
      "epoch n405: \n",
      "Train loss: 3.483858017716557e-05\n",
      "epoch n420: \n",
      "Train loss: 3.49614565493539e-05\n",
      "epoch n435: \n",
      "Train loss: 1.666365278651938e-05\n",
      "epoch n450: \n",
      "Train loss: 4.757244460051879e-05\n",
      "epoch n465: \n",
      "Train loss: 6.35339820291847e-05\n",
      "epoch n480: \n",
      "Train loss: 4.069104033987969e-05\n",
      "epoch n495: \n",
      "Train loss: 2.7321333618601784e-05\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "lr_base = 0.01\n",
    "weight_decay = 1e-4\n",
    "lr_decay_factor=0.1 \n",
    "lr_decay_epochs=[150, 250, 350]\n",
    "epochs = 500\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def adjust_learning_rate_2(optimizer, epoch):\n",
    "        \"\"\"decrease the learning rate \"\"\"\n",
    "        lr = lr_base\n",
    "\n",
    "        num_decays = len(lr_decay_epochs)\n",
    "        for decay_i in range(num_decays):\n",
    "            if epoch >= lr_decay_epochs[decay_i]:\n",
    "                lr = lr * lr_decay_factor\n",
    "            #end if epoch\n",
    "        #end for decay_i\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "trainset = labels_Dataset()\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "PATH = \"models/embed/embed128_RPM.pth\"\n",
    "\n",
    "net_embed = ResNet18_embed()\n",
    "net_embed = nn.DataParallel(net_embed)\n",
    "\n",
    "cp = torch.load(PATH)\n",
    "net_embed.load_state_dict(cp['net_state_dict'])\n",
    "\n",
    "net_embed.eval()\n",
    "net_h2y = net_embed.module.h2y #convert embedding labels to original labels\n",
    "net_y2h = model_y2h().to(device)\n",
    "optimizer_y2h = torch.optim.SGD(net_y2h.parameters(), lr = lr_base, momentum= 0.9, weight_decay=weight_decay)\n",
    "\n",
    "for ep in range(epochs):\n",
    "    net_y2h.train()\n",
    "    adjust_learning_rate_2(optimizer_y2h, ep)\n",
    "    \n",
    "    labels = next(iter(trainloader)).type(torch.float).to(device)\n",
    "    batch_size_curr = len(labels)\n",
    "    batch_gamma = torch.normal(0, 0.2, size = (batch_size_curr, 1)).to(device)\n",
    "    labels_noised = torch.clamp(labels + batch_gamma, 0.0, 1.0)\n",
    "    \n",
    "    #plt.hist(labels_noised.view(-1).tolist())\n",
    "    \n",
    "    out = net_y2h(labels_noised)\n",
    "    labels_noised_rec = net_h2y(out)\n",
    "    \n",
    "    loss = nn.MSELoss()(labels_noised_rec, labels_noised) #tester L1 loss\n",
    "    optimizer_y2h.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_y2h.step()\n",
    "    \n",
    "    if(ep%15 == 0):\n",
    "        print(f\"epoch n{ep}: \\nTrain loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving network\n",
    "\n",
    "PATH = \"models/y2h/y2h128_RPM.pth\"\n",
    "torch.save({\n",
    "                    'epoch': ep,\n",
    "                    'net_state_dict': net_y2h.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer_y2h.state_dict(),\n",
    "                    'rng_state': torch.get_rng_state()\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing of data embedding inversability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'distribution of labels with an error > 0.005')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"models/embed/embed128_RPM.pth\"\n",
    "\n",
    "net_embed = ResNet18_embed()\n",
    "net_embed = nn.DataParallel(net_embed)\n",
    "\n",
    "cp = torch.load(PATH)\n",
    "net_embed.load_state_dict(cp['net_state_dict'])\n",
    "\n",
    "net_h2y = net_embed.module.h2y\n",
    "\n",
    "PATH = \"models/y2h/y2h128_RPM.pth\"\n",
    "\n",
    "net_y2h = model_y2h().to(device)\n",
    "cpy = torch.load(PATH)\n",
    "net_y2h.load_state_dict(cpy['net_state_dict'])\n",
    "\n",
    "test = torch.rand(size = (5000,1)).to(device)\n",
    "test_h = net_y2h(test)\n",
    "test_rec = net_h2y(test_h)\n",
    "\n",
    "f = plt.figure(figsize=(15,5))\n",
    "ax = f.add_subplot(121)\n",
    "ax2 = f.add_subplot(122)\n",
    "\n",
    "#mettre valeur absolue L2 ?\n",
    "ax.hist((test - test_rec).view(-1).tolist(), np.arange(-0.03,0.03,(0.03*2)/30))[2]\n",
    "ax.set_title('reconstruction error')\n",
    "\n",
    "\n",
    "ax2.hist(test[abs(test - test_rec) > 0.005].view(-1).tolist(), np.arange(0.0,1.0+1/300,1/300))[2]\n",
    "ax2.set_title('distribution of labels with an error > 0.005')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y2h model is very efficient at inversing the mapping 128 -> 1 of the net_embed.module.h2y layer <br>\n",
    "We also see that most of the error comes from the edge cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
